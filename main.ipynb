{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import rdkit \n",
    "import multiprocessing\n",
    "import copy\n",
    "import math \n",
    "import random\n",
    "import pickle \n",
    "import utils \n",
    "import model \n",
    "from utils import parallel_f, get_mol, replace_atom, tokenize, pad, MyDataset, get_dic, clones\n",
    "from model import TransformerVAE, device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_smi_list(path) :\n",
    "    with open(path, 'r') as file :\n",
    "        return [smi[:-1] for smi in file.readlines()]\n",
    "    \n",
    "\n",
    "def replace_atom(smi) :\n",
    "    return smi.replace('Cl', 'L').replace('Br', 'R') \n",
    "\n",
    "def get_mol(smi) :\n",
    "    return rdkit.Chem.MolFromSmiles(smi)\n",
    "\n",
    "def parallel_f(f, input_list) :\n",
    "    pool = multiprocessing.Pool()\n",
    "    return pool.map(f, input_list)\n",
    "\n",
    "def get_dic(smi_list) :\n",
    "    dic = {'<START>': 0, '<END>': 1, '<PAD>': 2}\n",
    "    for smi in smi_list :\n",
    "        for char in smi :\n",
    "            if char not in dic :\n",
    "                dic[char] = len(dic) \n",
    "    return dic \n",
    "\n",
    "def tokenize(smi) :\n",
    "    return [0] + [smi_dic[char] for char in smi] + [1]\n",
    "\n",
    "def pad(smi) :\n",
    "    return smi + [2] * (max_len - len(smi))\n",
    "\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0\n",
    "\n",
    "\n",
    "def get_mask(target) :\n",
    "    mask = (target != smi_dic['<PAD>']).unsqueeze(-2)\n",
    "    return mask & subsequent_mask(target.size(-1)).type_as(mask.data)\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, token_list) :\n",
    "        self.token_list = token_list\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.token_list)\n",
    "\n",
    "    def __getitem__(self, idx) :   \n",
    "        return torch.tensor(self.token_list[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 373814\n"
     ]
    }
   ],
   "source": [
    "# Load ChEMBL dataset\n",
    "\n",
    "with open('data/chembl24_canon_train.pickle', 'rb') as file :\n",
    "    smi_list = pickle.load(file) \n",
    "\n",
    "\n",
    "smi_list = [smi for smi in smi_list if len(smi) < 40] # Choose only smiles with length < 40\n",
    "\n",
    "print(f'Number of data: {len(smi_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smi_list = get_smi_list('data/ADAGRASIB_SMILES.txt')\n",
    "smi_dic = get_dic(smi_list)\n",
    "\n",
    "inv_dic = {v:k for k, v in smi_dic.items()}\n",
    "\n",
    "token_list = parallel_f(tokenize, smi_list)\n",
    "max_len = len(max(token_list, key=len))\n",
    "token_list = parallel_f(pad, token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mask(target, smi_dic) :\n",
    "    mask = (target != smi_dic['<PAD>']).unsqueeze(-2)\n",
    "    return mask & subsequent_mask(target.size(-1)).type_as(mask.data)\n",
    "\n",
    "def frange_cycle_cosine(start, stop, n_epoch, n_cycle=4, ratio=0.5):\n",
    "    L = np.ones(n_epoch)\n",
    "    period = n_epoch/n_cycle\n",
    "    step = (stop-start)/(period*ratio) # step is in [0,1]\n",
    "    \n",
    "    # transform into [0, pi] for plots: \n",
    "\n",
    "    for c in range(n_cycle):\n",
    "\n",
    "        v , i = start , 0\n",
    "        while v <= stop:\n",
    "            L[int(i+c*period)] = 0.5-.5*math.cos(v*math.pi)\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L    \n",
    "\n",
    "\n",
    "def gen_beta(start, end, T1, T2, T3):\n",
    "    for i in range(T1):\n",
    "        yield start\n",
    "    log_s = np.log(start)\n",
    "    log_e = np.log(end)\n",
    "    T = T2 - T1\n",
    "    AT = T3 - T1\n",
    "    for i in range(T):\n",
    "        cur_beta = np.exp(log_s + (log_e - log_s) / AT * i)\n",
    "        yield cur_beta\n",
    "\n",
    "    T = T3 - T2\n",
    "    delta_beta = (end - cur_beta) / T\n",
    "    for i in range(T):\n",
    "        cur_beta += delta_beta\n",
    "        yield cur_beta\n",
    "\n",
    "    while True:\n",
    "        yield end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "dataset = MyDataset(token_list)\n",
    "train_set, val_set = random_split(dataset, [0.9, 0.1])\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import math \n",
    "import utils\n",
    "from utils import get_mask, clones\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class Attention(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head) :\n",
    "        super(Attention, self).__init__()\n",
    "        assert dim_model % num_head == 0, 'dim_model % num_head != 0'\n",
    "        self.dim_model = dim_model\n",
    "        self.num_head = num_head\n",
    "        self.dim_head = dim_model // num_head\n",
    "\n",
    "        self.Q = nn.Linear(dim_model, dim_model)\n",
    "        self.K = nn.Linear(dim_model, dim_model)\n",
    "        self.V = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "        self.out = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask = None) :\n",
    "        B = Q.size(0) \n",
    "\n",
    "        Q, K, V = self.Q(Q), self.K(K), self.V(V)\n",
    "\n",
    "        len_Q, len_K, len_V = Q.size(1), K.size(1), V.size(1)\n",
    "\n",
    "        Q = Q.reshape(B, self.num_head, len_Q, self.dim_head)\n",
    "        K = K.reshape(B, self.num_head, len_K, self.dim_head)\n",
    "        V = V.reshape(B, self.num_head, len_V, self.dim_head)\n",
    "        \n",
    "        K_T = K.transpose(2,3).contiguous()\n",
    "\n",
    "        attn_score = Q @ K_T\n",
    "\n",
    "        attn_score = attn_score / (self.dim_head ** 1/2)\n",
    "        if mask is not None :\n",
    "            attn_score = attn_score.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn_distribution = torch.softmax(attn_score, dim = -1)\n",
    "\n",
    "        attn = attn_distribution @ V\n",
    "\n",
    "        attn = attn.reshape(B, len_Q, self.num_head * self.dim_head)\n",
    "        \n",
    "        attn = self.out(attn)\n",
    "\n",
    "        return attn, attn_distribution\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class EncoderOne(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_latent, num_head, num_layer, dropout) :\n",
    "        super(EncoderOne, self).__init__()\n",
    "\n",
    "        self.layers = clones(EncoderOneLayer(dim_model, dim_latent, num_head, dropout), num_layer)\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_latent),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(dim_latent),\n",
    "        )\n",
    "        self.sigma = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_latent),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(dim_latent),\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        for layer in self.layers : \n",
    "            x = layer(x) \n",
    "\n",
    "        return self.mu(x), self.sigma(x) \n",
    "\n",
    "\n",
    "class EncoderOneLayer(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_latent, num_head, dropout) :\n",
    "        super(EncoderOneLayer, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim_model)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.self_attn = Attention(dim_model, num_head) \n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_model, dim_model)\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_model) \n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.norm1(x)\n",
    "        attn, self_attn = self.self_attn(x, x, x)\n",
    "        x = x + self.drop1(attn)\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_foward(x)\n",
    "        x = x + self.drop2(x)   \n",
    "\n",
    "        x = self.norm3(x)\n",
    "\n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class EncoderTwo(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_latent, num_head, num_layer, dropout) :\n",
    "        super(EncoderTwo, self).__init__()\n",
    "\n",
    "        self.layers = clones(EncoderTwoLayer(dim_latent, dim_latent, num_head, dropout), num_layer)\n",
    "        self.expand = EncoderTwoLayer(dim_model, dim_latent, num_head, dropout)\n",
    "\n",
    "    def forward(self, z) :\n",
    "        for layer in self.layers : \n",
    "            z = layer(z) \n",
    "        x = self.expand(z)\n",
    "        return x \n",
    "\n",
    "class EncoderTwoLayer(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_latent, num_head, dropout) :\n",
    "        super(EncoderTwoLayer, self).__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_latent)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.self_attn = Attention(dim_latent, num_head) \n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_latent)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_latent, dim_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(dim_model, dim_model)\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_model)       \n",
    "\n",
    "    def forward(self, z) :\n",
    "        z = self.norm1(z)\n",
    "        attn, self_attn = self.self_attn(z, z, z)\n",
    "        z = z + self.drop1(attn)\n",
    "\n",
    "        z = self.norm2(z)\n",
    "        z = self.feed_foward(z)\n",
    "        z = z + self.drop2(z)   \n",
    "\n",
    "        z = self.norm3(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_expansion, num_head, num_layer, dropout, smi_dic) :\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = clones(DecoderLayer(dim_model, dim_expansion, num_head, dropout, smi_dic), num_layer) \n",
    "\n",
    "    def forward(self, memory, target, mask) :\n",
    "        for layer in self.layers : \n",
    "            target = layer(memory, target, mask) \n",
    "        return target\n",
    "\n",
    "class DecoderLayer(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_expansion, num_head, dropout, smi_dic) :\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_model)   \n",
    "        self.self_attn = Attention(dim_model, num_head)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.cross_attn = Attention(dim_model, num_head)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_model)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_expansion),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(dim_expansion, dim_model),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, memory, target, mask) :\n",
    "        target = self.norm1(target)\n",
    "        attn, self_attn = self.self_attn(target, target, target, mask)\n",
    "        target = target + self.drop1(attn)\n",
    "\n",
    "        target = self.norm2(target)\n",
    "        attn, cross_attn = self.cross_attn(target, memory, memory)\n",
    "        target = target + self.drop2(attn)\n",
    "\n",
    "        target = self.norm3(target)\n",
    "        target = self.feed_foward(target)\n",
    "        target = target + self.drop3(target)\n",
    "\n",
    "        return target\n",
    "\n",
    "\n",
    "class TransformerVAE(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_expansion, dim_latent, num_head, num_layer, dropout, smi_dic) :\n",
    "        super(TransformerVAE, self).__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.smi_dic = smi_dic\n",
    "        \n",
    "        self.embed = nn.Embedding(len(smi_dic), dim_model)\n",
    "        self.pos = PositionalEncoding(dim_model, dropout)\n",
    "\n",
    "        self.encoder_1 = EncoderOne(dim_model, dim_latent, num_head, num_layer, dropout)\n",
    "\n",
    "        self.pos_z = PositionalEncoding(dim_latent, dropout)\n",
    "\n",
    "        self.encoder_2 = EncoderTwo(dim_model, dim_latent, num_head, num_layer, dropout)\n",
    "\n",
    "        self.embed_tgt = nn.Embedding(len(smi_dic), dim_model) \n",
    "        self.pos_tgt = PositionalEncoding(dim_model, dropout)\n",
    "\n",
    "        self.decoder = Decoder(dim_model, dim_expansion, num_head, num_layer, dropout, smi_dic) \n",
    "\n",
    "        self.norm = nn.LayerNorm(dim_model)\n",
    "        self.proj = nn.Linear(dim_model, len(smi_dic))\n",
    "\n",
    "    def reparameterization(self, mu, sigma) :\n",
    "        eps = torch.rand_like(sigma).to(device)\n",
    "        z = mu + torch.exp(sigma) * eps\n",
    "        return z \n",
    "\n",
    "    def get_mask(self, target, smi_dic) :\n",
    "        mask = (target != smi_dic['<PAD>']).unsqueeze(-2)\n",
    "        return mask & subsequent_mask(target.size(-1)).type_as(mask.data)\n",
    "    \n",
    "    def inference(self, z, target) :\n",
    "        z = self.pos_z(z) \n",
    "\n",
    "        memory = self.encoder_2(z) \n",
    "\n",
    "        mask = self.get_mask(target, self.smi_dic)\n",
    "        mask = mask.unsqueeze(1).to(device) \n",
    "\n",
    "        target = self.embed_tgt(target) * (self.dim_model ** 0.5)\n",
    "        target = self.pos_tgt(target)\n",
    "\n",
    "        target = self.decoder(memory, target, mask) \n",
    "\n",
    "        target = self.norm(target) \n",
    "        target = self.proj(target)\n",
    "        target = F.log_softmax(target, dim = -1)\n",
    "\n",
    "        return target\n",
    "    \n",
    "    def forward(self, x, target) :\n",
    "        x = self.embed(x) * (self.dim_model ** 0.5)   \n",
    "        x = self.pos(x) \n",
    "\n",
    "        mu, sigma = self.encoder_1(x) \n",
    "        z = self.reparameterization(mu, sigma) \n",
    "\n",
    "        z = self.pos_z(z) \n",
    "\n",
    "        memory = self.encoder_2(z) \n",
    "\n",
    "        mask = self.get_mask(target, self.smi_dic)\n",
    "        mask = mask.unsqueeze(1).to(device) \n",
    "\n",
    "        target = self.embed_tgt(target) * (self.dim_model ** 0.5)\n",
    "        target = self.pos_tgt(target)\n",
    "\n",
    "        target = self.decoder(memory, target, mask) \n",
    "\n",
    "        target = self.norm(target) \n",
    "        target = self.proj(target)\n",
    "        target = F.log_softmax(target, dim = -1)\n",
    "\n",
    "        return target, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerVAE(dim_model=256,\n",
    "                       dim_expansion=256,\n",
    "                       dim_latent = 128,\n",
    "                       num_head=8,\n",
    "                       num_layer=2,\n",
    "                       dropout=0.5,\n",
    "                       smi_dic=smi_dic).to(device)\n",
    "\n",
    "# loss_fn = nn.NLLLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.0003) \n",
    "\n",
    "\n",
    "def loss_fn(pred, tgt, mu, sigma, beta) :\n",
    "    reconstruction_loss = F.nll_loss(pred.reshape(-1, len(smi_dic)), tgt[:, 1:].reshape(-1), reduction='sum')\n",
    "    kl_loss = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp()) \n",
    "    return  reconstruction_loss + kl_loss * beta \n",
    "NUM_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O)1Occcccccccccccccccccccccccccccccccccc\n",
      "cccccccccccccccccccccccccccccccccccccccc\n",
      "cccccccccccccccccccccccccccccccccccccccc\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "C(=O)CCC(=O)CC(=O)CC(=O)C(=O)C(=O)C)CCC(\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "Cccccccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "C(=O)ccccccccccccccccccccccccccccccccccc\n",
      "CC1C(=O)C1cccccccccccccccccccccccccccccc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) :\n\u001b[0;32m---> 27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     _, idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(out, \u001b[38;5;241m1\u001b[39m, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "Cell \u001b[0;32mIn [8], line 268\u001b[0m, in \u001b[0;36mTransformerVAE.inference\u001b[0;34m(self, z, target)\u001b[0m\n\u001b[1;32m    264\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_z(z) \n\u001b[1;32m    266\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_2(z) \n\u001b[0;32m--> 268\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmi_dic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m    271\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tgt(target) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_model \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "Cell \u001b[0;32mIn [8], line 261\u001b[0m, in \u001b[0;36mTransformerVAE.get_mask\u001b[0;34m(self, target, smi_dic)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, smi_dic) :\n\u001b[1;32m    260\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m!=\u001b[39m smi_dic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;241m&\u001b[39m \u001b[43msubsequent_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype_as(mask\u001b[38;5;241m.\u001b[39mdata)\n",
      "Cell \u001b[0;32mIn [3], line 35\u001b[0m, in \u001b[0;36msubsequent_mask\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubsequent_mask\u001b[39m(size):\n\u001b[1;32m     34\u001b[0m     attn_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, size, size)\n\u001b[0;32m---> 35\u001b[0m     subsequent_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiagonal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(\n\u001b[1;32m     36\u001b[0m         torch\u001b[38;5;241m.\u001b[39muint8\n\u001b[1;32m     37\u001b[0m     )\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subsequent_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "beta_np_cyc = frange_cycle_cosine(0.0, 1.0, NUM_EPOCH, 1)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1) :\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    beta = beta_np_cyc[epoch-1]\n",
    "    for i, input in enumerate(train_loader) :\n",
    "        model.train()\n",
    "\n",
    "        input = input.to(device)\n",
    "        pred, mu, sigma = model(input, input[:, :-1])\n",
    "\n",
    "        loss = loss_fn(pred, input, mu, sigma, beta)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        if random.random() < 0.5: \n",
    "            z = torch.randn(1, max_len, 128).to(device)\n",
    "            target = torch.zeros(1, 1, dtype=torch.long).to(device)\n",
    "\n",
    "            for i in range(max_len - 1) :\n",
    "                out = model.inference(z, target)\n",
    "                _, idx = torch.topk(out, 1, dim = -1)\n",
    "                idx = idx[:, -1, :]\n",
    "                target = torch.cat([target, idx], dim = 1)\n",
    "\n",
    "            target = target.squeeze(0).tolist()\n",
    "            smiles = ''.join([inv_dic[i] for i in target])\n",
    "            smiles = smiles.replace(\"<START>\", \"\").replace(\"<PAD>\", \"\").replace(\"<END>\",\"\")\n",
    "            # valid = \"Valid\" if get_mol(smiles) else \"Not\"\n",
    "            print(f'{smiles}')\n",
    "    print(f'epoch : {epoch}, train loss : {train_loss / len(train_loader)} val loss : {val_loss / len(val_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FiiclH2Fl67sPSS5S6BFF#HcPSSH2s#6[PsH', 'FCFFpi2pHI6HHi3p]lsHFiSFI66HcF(i-6r', 'sSs6HSFHn[-Hrl=#FNc6-7HS7cscF[-i(S6FFe2', 'irSl6-rii7F4Ss2Fce[6FcHi6F6P(Fi#lHFr[', 'H6S#bc1csFbFSSl6cls[l-[cBsi#i2F=-(66[6', 'F#Nr4HlbssHSF6b+6+SFrN+[c6rSP6O2[27SO', '(riCSPs(-6FO[-6[Nsci7262S626isi#b-lB', 'rF[i6i5+lP-ccScHsFs)Bs[6cHs6]HlSoS', '[l6PPIr[7s67-[=(c626ClHSSccHH#6S2Sr', 'c5[#Fs32FFF2F2[-iiP6SScH)(7HFNr1sOic#', 'rHslclli1Hi#SF7is=F4c+F([rNii76lH-P66F', 'iS7FPr]F-PisS)rcl67ii66[#6rFc6]csSri-i', 'SsF+i36##Fb266cFHHHiIHs2i]p62#ll2--[', '6S[72#slp6sBF]-SO2nFi-1c2eircb3Si-7S', '76P6s=2Ic[s#i6l#SHiiiCCii6i5sFli', 'H42-co2i77ii2Fr626iri6e6rc=2ol++S=', '+sFF6(s-2s4-BCC6F6clsbFN24i#S6]-r', 'SI7sp56riBO6criS[Oiii6SFO7HiSH6Fi]C#6', '=r-7lcS=i-HoH16c][6s[sl6iii[6=7672F#ii', '6r[rN6irlcirSFSSF76]2r[6S5[)sF7cFiO', '7FN=P6eFHn6liSHn--=7]BFceI2isH6iisHb', 'nbiiPNSiFHn#7SO[=Ccci3p=l7Sr-S6s6CH-r', 'Fcpi7F2si462cOHsOcS6i66HFciF3iic-s6N2', 's+26I2iis+HP26s-eSrHsS[=IH#C-SH[ls', '[6i+-csSSi3i6Cll#6rSrF[-sHcScl2=Ocr6sp', 'FsFicil2r-icBSNi+ccilcl26HHsiFN+b[#(6', '3Pls-+cNFFCl6s2H7iF6rl-][l]66s#S-Cl(O-', '+cs6r6-PcsSFs6rIc+HcciBbc6]2ss72c]]', 'i26i6O=eCONNFSi6r)6H6SH]r6icH7--ioc', '6c3S6ir+HiS)6#O6pP6Fe([bcFBC6S7ecH6Sc6l', 'e[2s+Silp=s2pIsIlli=o6oSP=seF6l2Hlic6S6', 'FFci6[[HF]i6HSs[NrHS-(+iS26rbHl7-iO-6S', 'ibNH+FlHci-4#IHl6[=--I6[io#F246pisFeH', '366lsF1#sOi27l2cIi[#sN6HS2liiiS(e27', '24N7#=ssF[rl66NP6iSP(H-N-7FlNlBn(I266H', 'rl[e]i(ce2sP2FbH65sliP[HSSI-c2csi+22B66-', 'ssiNSr7Sr6PSi-s=S6HSi+#FS626-(6(ib#-F5[', 'eil2s[-67S-6l26l6Icpli7SFF1i-HlB#b=ir+I', 'F3P=i6s-6Pos-+cHFeSsl1oHPiC#F5#Fls+S6', '6iiFF7i62lrFNS[FSH[cSSHi(i76N--i#6+b', 'SSSF2O2oFF7(irciS26iPsi-6rbs7)i7Fi+27', '6s46e#-piccs6Hsrebi36S7FSS2c6i2Ss76oHH', 'HHi7-NF)-6i6HcIncFr6()s6H#i6ScFScc--', 'ces-6rp)BeF(2rii6lrlSi-F2bFlcc-76Fbl', '7[s6Cs-3Hr77HS6+ciOFSiiriS6Ocs]F7)N-H', 'F+c67iF-l)s-HHbr-rNiS)I[iii225F3bsH6cHs', '#NHi#sS+IrcB3i7r2+eHCFi(c62-C+2l[66FeF', '7ss(#FicS2OPicsSsFSc7i2-[3HisF#i727H6', 'sPsFPi3HlCNsS6-llr6[S]rFSlcIc6-46[-2', 'HPl=4F=l62OHbSrSFBcclsPHi7c[c6c67i(l', '2Pi3cCr6PB+7ip6IllB2[l(lO]-+ic6sOrp6]', '2-5sSFrrHF-F-Fb[r-F2es=H(3SrHHe##FsCc', 'B(PF6#IHSiisIFs7in]lIO6F-ei6r67s7S-7', '-7rFsp62e=iiCI-733lIlii6H77iOiFcOlss', 'F-6ciece2-S6r#ieH(eiP7F267HP66S+Ss#', '4S3iilsH]N-(6ercSiFNe-Fr63]26FlsC6ce', 'es2c-6i6oSi-r-lblISlPrl-iPI7IHFH6', '(C-pcil2-Hn[o6Hs(c6o=becIclcO2Si(ecc', ']6NFFHSHs6O[FI6iHS7#sSrFS6i-S+cccIc', 'FFF3pFS7F[i6S(#N(csiir#F+FFSs5Firl', 'llS[F7rp6i6lr2+S#[(SI2HeOl4Sleo[-676i-S-', 'sis6Hs6c2#[i6]cSii##INIs2i(rrNiHc[6', ']6HN=SlcH56cH#6-6ON66]ciH5HS(6c4]i7ee', 'F#H#c6HilNssH6Ho6Fr-nO2Pir6FFrcc)-r', '6i6c2[c+6l7Sr(B7F-7r2S766-lFHiBpH6#(', '4HP+66(F6SocCc6[cc-7c26c67FrHS7)C-2', '-FlisHscsSOs--7i#c2SF+lFic6iFsFs)icc', 'iNsoH6s6H7Cicc#[sH6H6rFii#[]6Hi+6lB', '66ir]+lli#2s[6-bFri#S=rN-2sS7cc-24i2sSB', '-S-Fllc(F6]F6NlisiiC2Hc2]FS=rc6c-lc=6-', 'i+2[cF=lFpHsF4cc6s#3s677]r6773bHs2S=7', '6r-bF6c26S2ci6S#C[B6]rcslsosHe6H6', 'cSS2Se--S-sFIC]lIP7=osciiOHlb72lirN#', '4Hcl-rpli3cs[2sH]-rb6FiH(lFb]e-SlSi7', 'F[6FS4Sie6l6FicSSI6SF-Fi1H1ilcO6677S', '667iSF63-6FFn77SllIFHcc6s-lSCFCH-Ni-H[', 'rc2N3Frs=N667#4-lS6s6S=Pli#lsN66r[H', 'S7[NHS-2#-N2liSFF=SIHsPiN6leF[(P3c((', 'p(NccllcP6io6llie7iO6[FF76(l(S[ciliC6i', 'FeSHF-lc6[#+iHSF#isF7-i2BF#667o2eF[I(s', 'O2cI6oPFS6r6ICo66rFPF+ilO2lcSP6lF6p-', 'ici-6#FFN66cc+o2F6l-246HIN]2cSFsr7-6', 'Isli7FiiNcsH+ePi2[bHnFi7sB6-i--+rli]cI', 'FS-66Pb-B3#-cc+ccS-6cs6S]nSir-63rFCSlsH', 'FcSri66Il=N2SFici-r-726#FiHl2O6N7rcS', 'c-F6cc6l+26[cN6]ciH=Se67H6ioiFlsoSi7', 'scs6l=FibFOrSP77B6(s2265reSl6r]CiFi+2]', 'HsPi7-pNl6i7]r[O-sisc6ii5+6Hi-icHHi]l', 'N+FciiI6S5[siSiii7Hsc-+6S[H7He]-6-r', '7i6S[-)lF[i2P7F7FlicNS#ce]#F=Sp-SSs6l', '-BiO6#6cF-)oi-6i23S-llSn](S6cs-sFlo6IF', '-65-ss-iHo3S-s6-N-Hi#sp-#ciS=r3Nb27+ir', 'ecHHHSccsSii77es-sFlc--H+F+llnF#I-677O', '23oB]-c+eOSir6Ns6rlr7iS2+]lHlI-s6', 'Sr)ci#FsOHrOHscsH6csCi622l-66i6iP(oHs', 'OcF7#rSHsiHF+c[#26il(S-[SHirFSHi676is', '+nHiSscFFS#6rPlS-r-Fc6S7)--inp+Oisp6cic', 'FNHSOiBiS6l6N(Slisie7C6ci7)cNSsFO672ci', 'ciec2(e[slicHS]N-6H[[P6iblSF6IFHc24p6[', ']H]eCSs-c-iss(726i7lnP67iF7rsp66rF]sss', '7ls#cNi+FIlrSseS622OSF26i6sHSis7ScIFPFS', 'iFFFSsb-P7F3Sl6-H6Hi-6iHHNSFl67Ii[', '7rF[6)Fl6[SrFs676B]iSSS6(H2ii7rSbss5)6', 'cnH[6+6F6i2sO2IOiisS6B2]S77+SS-7+2s+', 'srNio2i#-SS#-6)F=Os2n+S6]HSSPSS-6Fb66S', 'Oi3I6Pe#7F76HFN=FrPN7s6#rOIpSsS+S', 'P-67F6F)2p+3H6ccl5I]c)i3ic2PSolc2lcCsO', '-+cc2-]]c-Fi-olFl466lc6iiPC267[FirF', 'H2PN2FB6737I726#H2F=237H7r#Nil6#-6Hi+', '-lNsc#lcFlcsSiHF]Sic2IS66cFI1i6e#=s', 'i---6r][FcS#sSFi)i2SHibFO=N77OsS)occHHS#', '-4HF(-IOl26II2-ilC47(Hi26r6Pli7ns-1', '#]O]2rS6ri6llFH#lsSI66F[=rcS6Fl3FNF', 'r-SHc)I61l-lI7cSsHl6[6l=S-N-SNe-liC6SF', 's=ll-OH=ccSS3-(4ciHHFSp2ls[67cOl67s(S', '6r#Ss-2F--Se4HllH#ls[26]i#2IcSsli]rNF#', 'n6l2[-6Sp6r]SrHS6-7FSsP6cPc6lIlie(Nrl(', 'HSS-N-SHSSSrS4cS-ieF6I2+pilbF+O-ei7F(2', '#li7c-OnSFi+6FOcHF5F+iO)=nlFrHssF=s-', 'FSHiP6F#SF7l+rcN6SrHH[cll6iF2Hi#Nb7e', '576IBFsFC2[SI6e7FcNc=7]cFS25l[)F23iO', 'S6eplicri76l[i-c-B6-P7H266N+2lor7i', 's66PSs+26(#6#SNcci6FCs#iFi#7i667i3[67i2', 'F7ipr6FS[-iceNiFC]67ccciie6-4[[FSHSl', 'SBFiH6iis=ceSrcF76rSsPc3#es7S[Sn6i7F', 'iie6rrisiFNFFnSsiF]37l32sHi1l66FFI#c=l', '[i-b7F[b6#P6i=HS6Sl67+HS-7)(l-PiilsS#N', '2Fsi+(cp6=SIFcFi]][ilsP-sH6-4i(cS6cr6ci', 'r-=27sS76IHi)#)ilo=cOsiH[677[2ri-i', 'iiFs#r63(2ciOcll2ISFesF]II#7ec6#iHScc', '72NF#spPl26cNr[FNl6FF76FI6Isiib[cc]S47cF', 'e6Fbspi-e7cc7]I6Fr6FS2i6cs-p6l7oc6r[P(', '([ii1-7lHSpr7(FbH7iH626-66rlc2P6HC7ii', '[cC77F+s-roO6=l6ic[SsirsI[FSS3ielncc1=', 'SFcHiCoNsO-sNsi-6csrF]-r[-[cF6lSe2e7', 'rNS2[Fr-S6F67seF6S-F7s72-6ipl6iFFs+i', 'ccpir1elco7[-F66Os3e]i6HN7NsS6csl6H#6-', '6l-SlFccr6p6F(oc7lcp7l-O-27+NsF(s-S6', 'F[r#6S=F#H6HIOr#2sIicHciN6[=P-si7-ircn', 'S+llcSHs-e]6FS]l-]6I-Hl-O[Oi-iHSS6I6sO', '3cH[SINs26#S76FssleHHs7[si-7iS26l6', '22-(HS#cr#s6cSP-lFS76[sHHs66sIi+oF', 'c6OH)sicn67cS76csPi77FSHHN--osiFPS', 'lFS7c7C6]ci]-p6-76ioN+SeF2sP#i7s7s)c', 'PSpl2pSp]iHobi7rl6SSS+iIs6iN6+6#F#Sil', '6O-FSFci6cs(re6662S6[--]l6pIs[6]-=', 'r2SS[-SFil(#cH7cs5c+s]cc266I=ssiisS2eo6', 'S6372i[62eFrP67+FBSi62Pp#rF(-6-FiiF#', 'cl6SH(F66Fi6-7cFNcH66eii(l(PFSoSFe(', 'NpisSc--iibISci(2F6=eS62sipF#6cSSr+2s6', '2FC+F6oic62slF6FbH-Pi76cs42FIHFr+cF', '6Cc#6-iOeS6c26iiFrCFN+ci6-SHc3Ss+(c', 'H-s27cs6726CS7--iFiF6FeFNs6i4P66F#OFN6+', 'F76-2iFiciS#pil6c2+6+i#7si]2-6-6ecS7', 'bHOs-[ccsS=r-Ps6l67[Hsl7i6ccrN-HSSISO', 'FHssHcs6OoI=i6F4-S-[-sS3-lS2F2P', 'PSii]iscHbsic7Hn76S-ci6I6(rPrF3i-sF#67', '76HH6s6lcCsr+F7ii6-sOicls-[6c-3i(3b=H', 'F#]-+lNSsSlS7r6s7irFiP2so3liP5[FFbSir', '7H=-ii#)-Ne#HFciiFcFsr6F=2cSiBF6HslSS', 'O[F#-[6l2r6c76+[6F3S-7Nr[FHsp6S[ScHl', '7Nl626)F2SoIlFS-l7SSc+Hi6F6HFC-Fi=l', '6o2I6F#[[r7S6]6F(66sHFIHlFii7i#Scc', 'ccF6ccs#F27lPi66r26P6)c+67#S-ciiNF6r6', 'S-=OFc=I5FF7Nceic2IHcHsF6PCc-NHPlSSnFrN', 'cs-H]S4FPHH--I6Pi4FFiblP7cFC#iiH]Ss', 'SH7s67ice[C6Ilsil26]rlr66ic]ePS67', 's-e6F[r-7#F(2nF(iOiO2sS]lcP#S-62r7H[', 'crSSHS-iiOFSssb22S2Sr[(NrF=IF5cic7OFS6', '76i7SPBsl6psi6s6F(r6lSs6lS2272-6ir-Fb', '[Ssecci77is7iic26HPFNHiNPHsP6l6+22SSS6l', 'sF+]l]lNss2PH[i6lHiiiNcsSls-Sri]#2[FrF', 'l-FnOIsl=]l6CF2sc=e6rSF=r67s6CSi6c[-p', '=Fp2S+i-+csi]P6F6)i6OH#=o2nH]HiFrOF', '7s7c=rNiP6-Pe6pSs2S7S#-n-r-6FS-FOl6FC', 'Ic3[-eFr6SFi2FFNF+(6-HliH3riC-6iili6', 'FosrF#F3+-lc6Ni4Pr6S[IHl2F2-i-[pii', 'icss2iSp6]HSrcH7Fbl--nSC-6cbiSlisS6i#=P', '66c6HII[lc7cIr6FFis-77OIS767l6NcnHs--sP', '6s=SSFSS-bs7eiNi=6SFiCP+iO(F36-l]i6', 'bslHSOlcbPlFNn-P)[H-e7ll6l+sl[]6-N-S#', 'l6-HFS66ccHlrHS66s]=siF]-SH7Fc-HF[(#', 'esSScii66PpSF#66ci--spHSlpSirrc-7[[6l', 'eisiSiP-7-sie(s-slislHlS7[Fr6i]2(6Fp1c', 'l6sP[2Pr-l6HSP-s66C6-S6e5sH76#62P]cFSi', '7HFFlcs+6e-7i6[s(r66c+(ccCc-ibSsi66', '7obHIsii(sHSc#5FFcnrrlc=lSisFr-76#pi+F', 'rcC=6[sr6IBFoBFp6S#-ci#liPINs#rFSP2', 'e7[lHF26cI3H++2sSIH7sirbI--6Fe-[cliPSlr', 'ccs6si3CFbsricH=s2irHSP3#Hi2FN3l#OiF6#', 'N717FcsOiP7ss2[FFc+Nc#F6P[rc]ri6sH6I2', 'SF[7ss#2Fbii7[I66e6iSCrC7#sc=i]-(=(77Hc', '(Scli62srFFBcH=ls-SS-FF[(oSrSor(S#ric+s', 'BS+6liFSsSC(rP]Ssl6]NSiF(n6c-ciPI', '2Cil72nnSS62Ili-NsP7Fr667)767(s7is-ir', '-l]c6Hsbl-r+ISF66rl7e-777266SrccS2p', 'eri#SrsOcIHsrcS7H-Fi5SBc2F[6+1c2lB7r+66', 'bi6FciHF=i(scl+c6]#6P4l-NHS+c#F4H#FF]i6', 's(7riHS-i7isS6r56s+6OSibBFn-=li6-6H', '#lc(S7SF#+l[Hii4C7il6ri6##lcNFFb-266iiPH', '(cH7-O66[scrcF6ii[FS[#H6+o(cFe]CrcIC', 'i6[S7Bep-p26rrNiF]6PiF-l-eFb--6H2H=6]#7', '66iisPI[+6SO-c-F]Fii+#667PSI6r6N+Sclc]F', 'cc6F676c#c7[-S3-I6s6pp[nH+I6ibccN7SSs', ')-p-7i6c[#NN#F(=cFiH2Bl6SH-(F]S+(Fsli', 'H6F+(2p6HF-icFiiFsHH=6i2-7iHiHF(ScHbr', '[[+Oii=rF]ci6F#i+l+i-SSlrF6SF6r6lSeSs6#', 'iBHFincFbs6ii72psHsFHseSFnrSls2P-sBic', 'cHF4#O21lIslSl6#46oFN#ibc+cHs-7+6r-[-os', 'sH=rF6+l2p6iSc7-+ciib-r2=l6lcs[FB6-H', 'sPPc677oS6F--)[6rii6Psr]6S7eHsHIr]FSsl(', 'bIS7cciii+S[cs3ic76FsF6#S(csp-l[Oi', 'P27riOlSl6H]#FiibFS2SP-+5OcNlB-PSSSSc', '7ci1cOiHS6rc[so-7c25-6-6cS25sP-e6H[3-', '2ii26P2s-6clss2F[FS[o-+e2sc2il-SHe', 'ilsO+n6cic+-O7C4s+i1c6P66)6FIl(HlsHS2', 'FF-Ni3#s(e[cP7#6r7lrSss-e67SHc6-F(', 'r-H5S-6#-il[sI4Hs-]S2iS6cP776NliiIcS-6i6', 'sI62Pl6cscsp[7lc+l6Hi2B6IcS6r6Hl2(bSF', '(c-s-6F[FBSi7i6cssP=6clrOHSsssiFiO6N', '-sSF2BOo2PpO27iIBi6S27]FHcii6[ri6B6Sci', 'H-ssOIHsl-e+)HS-c#iH-S2iS66osS6sS7', 'Sr46FIsFN7H6HI2eP2S77sib-H[cH6ci-[r3-bB', '7se26e6-=#[l[r-Fi6p6B+ciH[pF=6PHSFsC', '+il[6]l7C6i-Ssies-Olc6Biie]i[6cFlc7c+', 'H(is2#-SS6FOlOiiS+Hs2l6ciP6cSr)sco6', 'sSpi6-i-PiBHFHc=6sir6lH7s26C=]2c6#H-iH', 'FisFI][cIO-F]6io]6S]i6l#isiis-Ni', '-)csO36IscI-P263F][lFbSriSsiOs-6ic666i', 'ri1FHr6CPFic#i6c+2r-sliFS-[lscp6l#lcFBI', 'Fs-P6cF26ciccHs536oSlioHe][NsSsioF-i', '4io(])l[=icn1]-pN-e)#6iIl6SFFi26eOi2e', '+S2S7Hii6s736-sHc2SS6r6O-rINFF3H-F[s[', 'cHc(-6c-Bii-7ICFb6rPSSn7iH67il6I66SO=FS', '7(6I6Sip6P26r-c=ll3cl-72F2rsnSF#(lPls-', 'rHH7i[62sOssSFlSF6Hi6spi-HSiF-7#6bi6l', '64H-IC6I67rslS#67IeiS-Ns-(seH6p2SH6', 'SSi-6PsIss#2NFrlrclS7F3S#S76ls-H6S#Nirc', '6e4r627cFbHS]c2[i6Ssi#Fil6S-NH+7+iH', 'SFO67FPS(r[-SscslF6sc]-Ss-SBc((Ci7', '#sH#lsl66i)csi-il6][c-l6PiFNslr6i2I', 'I76-2CbSlSHisc]FFci6O-72P6iPHiScISS6]', 'S7cF3llIcibF)cisi46-=c=lS(126-+6Pi6H=', 'bOb47H6rs6ibli#FS62sicpF6l[b[[-6i+i3ls7', '7i[HeF-SFsOHc-i-iioi6cHi6rs+H=I6ll[[s67', '+lPi]-l5-6s22HlcHFF=[PHSPH7SH(PO6[FP', ']S7ciSFClFFCF-oplSFCcSn[PiF-FN66e#-se', 's]s-lB-iSli6r6c]SNlB-6#6H6becPcFPH5+S', '6NsSF(ll6lir-6l6FFH-SFoFHscrrr7lF[', '6rNs-i=-FCF[Fiip2OH7es#)i6in4-(cO-ls', 'S2FSrH7HH=i6[lbIFIi5Fs#i6COc7nS2(3l', '6S6ci66566sr+ss]7IFlS6c7s-H+FSHScFB#c-', 'in6reFOSl=ccnlFFbi-lFirbi6Hi6HsHSi', 'F6riiciFP=c=[7-iebl-]NOio[6-2cs5He[', '6r(6i-lH6iH7+HiHSS-F7iI=osic67i-2i', '6HlciFsO-SNF]rS4[FFHNI6Ps--i667iiiclccF', '6OHcill6C6i]]Ssl6#27sFs-sc-O-S-4PSlFF', 'iOiO6-2+-=cr67S2ri7psc2([72PrSFr7cl67bs=', '[-7blPF[rbI--eN46lNi=6S2Fb7Fe3cssiSiS6', 'b-]HNo2O-4SHspcBO6Cc72Osicc-sirsbSls', '727i[l26c1leccr6S-lI27[sH)l7irFFSsFHcp6', 'P-6ssio=6#ioF(lBeIo7oH66bl6P6i+lsi5l', 'H6SS2Fc6l76(-7S7-er6FNIrSP7CNFN2isi', ']c2rcsSrlii7-6sS-PiOi]#sSS]#=lFrlse-766', 'PilHibF[+FSF6ci[rSi-(]S-=s-76-6-7S', 'F-]-csFI6SSsHcCi-)-2lS-=]cC7l6[6oi6cBSe', ']6FrSlpniB77icc=77sS7HI6Fl2lci)[#sc(F', '+66SiCH([FIFss#c[7cHs6i6-7OS-)i[=5sii=', 'ciscc#[I46#-[HcOSr6l676ci7P6+=csr62', 'FOFSSicl=Fib6]B26F66I6#l2lH-7-lFCibO', '47l-ci6He(-S#--H72PSebrcir2H67HN-=IlN6', 'F[spIiiFsiF(ilcii46NNFec553+r--2Hl2sF6Is', '6r++r-2[F-i(S76C-FSSiH=iHNicN]-l(F6i', '6Iii(=#F[32]FcSp6--6(HIF]F77FF+P6S', '26FSSS)Slci71sbPciP#NbHFO-]s-l6liipH6', 'sSp-2Frni4#6cnr2ilb-#6S-IF2ilHIIFrlH7S', 'sr=IsiIniirce3B6I[FF]lci-SHC2+s-s-7c6', '-6#-+)(-6bOrc[67SO377HlrSi[iHiNsHcl#iiI', '-SPSNOcS7l66(3N6HFr6criliF6(IF7nN', '[iiI6[F[S723-7csHH6]cc6ps6s7colcH-cs1r', ']FFsH-[Ss-CI)r6S6csire6c-7rci2lsHc', 'O6=SS#i[r-b(ii6SO-slsSlSl]2sc-p+ccSSIP', 'Hp5ii7cHr6rHNF2SSS6#2lHiobFPF(lpHrcc6+FP', '6rlb6cs-NrF-eiSiS4F[c3lniPSH]lir62[IFF', '6-6blcs32S6icF=#PIi7)2lH-iscS6=b#oiF', '6i#[SSci#FFliPl+H6[NscSi7sSib67ie', '6ss-)scH[FHSC(F-iniHS6sPcilCic6]7ic', 'cs[7ciorc56P]7]6s6iSl[H[icI#s6o3F', 'iiels6[c7FN6r-N=-ciib6FccH+6O)F#Oesl6', 'eS(6#6c-NFN6+-Fs+is(6S(SS6[(lsSnF]cO6', 'F=ccc-sH(6i3FsB6ss]HHl2OpN=Hcs+6SSOOsbF', 'NpiOH77Np-HsS-7ir6#s13l6[-r]#FrF6C-]l', '7rFFFcbiel#SS26cBreiS6bbleFib6F--s', 'O2cb26C2[--P7H7i4[Fi63i4-6Fs6SPF2s2csc', 'i2e[e(CHl6rl6[#26c324ccP-l6cOc4e7lFcHbi', 'n+6cPrH#([7s6iblcS]Slcc-i]6BH', 'Fc]-6rlPHsFr+lrs-rlS6S76FSP-Iil6ci(c', 'Hs-SpH6s-(cFNssNcIcciP[[6S77-SI+c#[e6-', 'IN]o62ib6i=l4Sl5-SBsF(SBSH6]cc7ilcs66S', 'Pp3Frlls2i-2i=FS(-bN=FiiH6ii67ciOceO', 'F-sFOB6rs67l-Nss]Fl=-S3F67s[6csi5C=r7', 'FIF+PCi6NiSHF6r-=P6ioio6S-cc6IFrF(cC-', 'FcibiS7e77FrNcO6-[Hcssi#c--l6s6F#OF#6FH', '#NOSSc2)#F2iBliFn6[s-PSSHsSH[b-l5]--P-[', 'r6)H+P7S-6rHO3Fil--l-6r6s4OP6=67[H4#', '1OrSlFF#[ilS6cH#6pS67e2Fp66=lS6iis4', 'c+)l6eOPI+S(l6r6sS7SO[iFC-ioFse-7liF', 'eCHsS7[=lie2s7C]i)2F66slbS66S]c-+l=l', 'SIliHsi-iiiHS-6ccr(S6-S#HO-Ss#66ll+-s-i', 'ss[bre=[Fe6S2s=HeNcF6-i2I-posSsi-6FI-', '26FF3FisFeF7S7-HHS#S7ic-Fl=PSS(i+7S', 'r-4S#2=FO-S#Piii#7cbH7][6iiScllI6-Fi[', 'Hl-[HF=67I#F=+ieH6]Fri6oi6r=c2IFn', '2sN32el-Fi)i2iPHrHs[##lioHSHHI#n6rF', 'H6S#1H-bl66iPsiP++PsSlSii-sSl6lSP#n-PS6', 'Fs#olBF-66+cO-P##F#csic6-7pS26B23cl6', 'r#NccbN]-lH6i6F#2ii(c-(i][iiileSHHH1Hr6', 'i77ce[-cO76s#c=c[lS6Fol6rC-csiilc(][', 'Fp+S(6lSFO6pPi6ii#6b--6o)l3bFP-iFFl-o', 'S2+6cPPr#(Bi+l62clsPp6cSlCicoics-6)', 'ip746+]B7i#2(bH=267cisFiS[#iPi76Piii', '72li+6[6sr[-SF666rsPF7HH]7bsSlii]F4S', '-#(7IIiHs6cpI6HScs2[=rScF6B-r6SH6i#i-76I', 'S-#6S[67256)4+6ls-e-ls6FNHS7i5NN+s2r72iF', '-6FiOHSISS-6i67HS+iFI6iS6#sS6F7Sibsl6e', 'n7-il7FNsscHi6277H3siF(F6]7e7H-l(lP', '#lceiH[c67ol5pFsHci#i#p7i1#6iss6iIci', '7c6loFFNsF6-7Pini6-i3OSHibb-(-6i6', 'S6-ciFibi(76lSi]rc(=ssFcO6el6F(6#c', 'F7iIcH72iPl6Ni6HsFc[F-sS6F]cs#O2si-', 'PcHFrce=6ccc##liINiiNp-SSe67r-l6F(66b(', 'cl6l6sFSlc(--l+7NN3F-6e[2iOsie#66rS', '-pHFl)62sHiSIoc(P2IsiiiiIci7B--Hs76#s', 'l2eiIicis-6]#6ioS6sCiSS+ecH23#i=67i77', '6#6s7iFNr66]F#+sil2HH6i66sisclni7iOse6', 'e)+i6rHlP6)=ii6eio)sNFHsl6S76IC[p7([F#H', ']72IH6ilHsc2-prrSH#SCB[6[s-26-2lss=', 'rs(67#FC6[6sbP6IHS(Oi[i76[oi+l3#FbN', 'isP6ll3)7iP(cs72ii#6rccI27626)7[6', 'SOsc6F+CFi([Fs-SrcllHl[s2ee-bc(ir6', 'S6SbFS-i-ii#6n])Fs2+sHs#5ePnPl[lbBseOb', '2i7C66#7ccHNc(i[F27FFF-ic77H4=Hic6cs', 'cc[+FF6sSFcsSsOibPScFlii#cFiFN7#i-iF', '2-PFc+FH]F==l6e6sSS[S-pbScSlcis6F6I[S6', 'crcl#rccFH-24iS[5s=iFsci-N6HHcl6i[cH', 'SFFS-Sr6HcHP6i5[i2cS+l6sH[ci67=IFN67', '+s666S2CNs+e6[ssFrS-+lsIiePS7F6[i6iF6B', 's6H6SlHe#FFC(2F#[bcsSFieSFs6l2S4l-F', 'PcOs6s67r-6C2sFO2bpcFF3FcHl2s+NP-s2ccB', 'r667PHcSsSspp6biH2H7Ni(-6(eFBieHS#sS7', '7Hes+cbils#SsSs]-]+H66HSPiCcl--Hl-[bBiii', 'r+sF26]ciiF(p6i6s[ls+2si4irF-[iic)IiO=N7', '6)6sSbFS2HPiFrF7][c#lB7r+Fsicee2N2e6eN', '6FcSsi73-F6e[FliN6]Hl6Fc-lp2HHNF3F6lHH', 'i6s+i7#--Hs66ii5SssceSl6-6+C-7eHieNc', 'c667ic=ccSS6NF]i26SiNl24SBi)26oFH77e6', '+bH-S[FiP6FN]CS7S7#6F--cl2i66s6#lisS', 'l2cF[r6iSHlH]oF[-6e6Sc6Fs-S7i-OipFc', '7llS-Sc-Hi#[r-2Ic]46]2lBINcS#F-6r67i', '2l6##-c-6i)66lo6iONS7sslls-7-(HHS6C46', 'F6Ss3HHs232sS466FiI3s(r6]O[I-r6]cNSii', 'FlIb6#s=-6]l6irs1NFP(#FsciOs1SS6F[7HF2', '#6H3iosOlss-Os)l6SBIF6c[N6[-[s627[-]', 'N-SSl[rc6CcN(FHcFFl6F]rr6lcsOccFHl2-H', 'N6r+l6PF]6rl#i6c#c#ccsi6F67slO6lScli[', 'ociF66--Srll-oFeS#6S3scrliBlH-6-7)=6', 'F6sNs26i4F]c6sl7i2cl=6l[r[sHi---SF#elS', 'pieF)S46]ci]l6S[HcBlSs+FbS#F##iF[H6F6F-i', '3FN[O27S2CFN6H#-7Hln#7N[F-#F]S=6Ccl[H', 'FNnb-Hss6-6pc#s2Fs6FiI[Slc2eNS6Fil', 'c6+S3B+-FIFN(FrFc677F7F4[2c3]iHsiiiS', '237762rcss(lii[PHcc+r6FNH+-lBsii277O1FF', 'l-F667FiP-l=ii-p-i]H76#-NlFiie6S+sHHi', ']C6IB[i]F46lSFB#ilB6icc6riiPels[Sl-76[', 'i=O67iPSB6PFSS2++--OcSis6c7-lHH)77H5', '2P-s7#FHSOi]o3FHScsF-Hiie7O-cHFSFs2i7', 'H#F]O2F6==6NIlSic76r2i6-e7rcl-siss72', 'cp[ln1-O6]slr3#]sHs6FC6PSi77SNF7eHc6S', '[i-eFir7OFHi76sFS67[rcip7F#HPPSsS[i6F', '1p6ie6c7lii+l#sc#S+(NS[SS76lHH6F#]-in6', 'Fs-HH-SiO=r32l6Pic=72-s67p=+OSss4sOHp', 'r[c2n]I6F]-ii6N6]i7--]cO2ssl2-rccOcF4n)', 'C2F6SBc+H[ic7i3iF66S6IirFB[bilPCrF2s', '7B+H67SS6il]FPs6Iss+s6r66cis6=6N6', 'Hl6s6[cclicSic27i7rS2[ISs6c=FeSFi-l(#', 'ir-6r[3lFH-O6c-i6i-67iN26IS-pS-2Fl(p2', 'SF#7r6iiicPFcielSi-si6b1siiiHSe+cpHC6#', '6FSSH7-i3B#6O-bSl(ri4#16c-6-r#e6-s=b2', 'r77-)Bs2s62sis6o]6lc=F[-H[i77rs(bs26#s', 'F#-S#cSFi66PHsH#c6rbiHlS#HSH6cO6-2rSNl', 'rl6isSiFF[2lb2i]i6H-76ric6P6#lHcHIH2', 'Srp26Sp[2r6[cS-s26+iP[B()cp--r[cbeooOF', 'S--p[BC26r666H+-l--6#S2r6=oP)H#ls]]6-i', 'NBr46#HslHP]Hr6NFrS6FS2cirPSiiN6F(#Fc', 'nr-lb72N6rc46rlS6l[-6sFH26FONciH2sr3c2c', 'i-Sl2-726ol66S#iN6-F]-(iiP+([S6+P-ss6rlH', 'Hl+HN6r7eIBiOr[s-pF-F+Bo-lS6iO6[F72sS1', '7iFNcsS6Fs+s-e6H-p-erBr][673i5cBOe6ibHF', 'HIBsSNN+F-(S7ss+-s6r+iSS27b67-7+HcpB26', '-6c-lcF2266c2HHsSi2ni+6lc(o6#s(6', 'PH6PbrS66[liFSlrc6cBs6-I#67e#66-6lPl', 'ec#--Hsc6#6OsSF2[iies-)HIi6F[rii2ls', '2FPi46Hi-S=l-O4rFlcoCs52bS+Pclc(cipi66r', 's6++s6SiooI2)6O)-s7rl#F6iFiOiC6-iir', '6FSp-irSe6c=nS(SnIrI6liH[rS-[circ-OiH-H', 'si73cnr7Ir4cI266[Bsi+cCbsSS#26r(c1-l', 'lHi62B-cPHiOc=oricc2i=7NSF716i=o-C3sio', 'rN+iciiS]b]eii+s2+icH)lsinS=#cs]c6iP6lc', 'Os27F[-P6=iirF(][N2SSSp[l22sCNF-[6', '-6#[HssF#Pi2Hic[NirNcFsSrS6rF]i-Isb2lHi', '6HC6irHs+s662rl6ic6(l7Ii72Plp[l6Ob3', 'l6H=NP#-2-icH2lFNHs[6(Ns2i77Icc-OiiiiH', '7FFHHscOFre-ss27ir(i22-FiiHisl6[677+l', ']#ilc6-iibHsFicr]-ci-SSsb6i+6iH#lbOsS6', '1[SiN[FS77ii67(7re7F-Hs[iislHcOC(6F6F', '-iH7NcF]clHie#llrC(7SprHSIrBFF-Pc4eiPlsH', 'biFiiPFF462-ln7iHc6l-F6H7c6F2e6i67iHSl', 'i+C6bHsc6ir(6+H-iFSO6ri(cccr74c2S7', 'e#Ic6Fp+-b76[6[Hc-72s2CH2F3Ssi]SsF', '6F[7-FNe#Hbs6cB6F[ccH=ls-sIlS26F2iisc6', 'l2SHSccFHs+FrFS67iIrCs+i]b[i6i-s6SS]26', 'Sl[Si=PPFcPSPc4Hs27i-F2p-2s2lNl+2NO-s', 'PSi[licrrli7iiSr--6cS(3l27rCHs)2eS-s--', '6F7[6Sii-o2ccCrN6[s6cSolci2FCccSF3NC', '=2O-iO==iS+7-irlccHONi6I6ibslc[[7Fl#[', '6nS6cH+iiH#iboSrib376c6-c-eisl76#P', '6(rpcN6]7F6cPllOF27i)oFBFNcelss67O', '1[3iis[F]#iccFs26SFscF6bS6C5FISrF6bHsH7', '2Fp-O6li2e-ccF]F(c[s66Snrc6rH6-6=[22l', '-i2b(eF]l=i(lFCIF3]F7l66#Occ[bOH-iP', 'n6CbFir766li+7Hl6r-3c[rlp#72S7N-(l2B', 'bc6l(-i4NF4(-NlI6H6P-e26-i46[ccOSiSs', 'SHc#6[ii(oNbiPrCC6[rsl[BO2iie2ir]c[', 'FiiF2s6b22F67l6rl6i+-#iPic#irHF6lSF][4-r', '2P(lS6IsC=C)F#PFec56N66IS-[=c-s[7cs', 'sFsiBciciS-FFcSFBIFIiO-iPc2Hic2OSHSF626(', 'Si7S-[nil6r7ie]SlO6=P(2FIc]ics+(+F6', ')627SSB23Fi6cs-bl7e)7cSH6#c2s-rclnccS', 'sSF=ssi#N#-SiHi4627c+b6cn72=7r#cSsSF', 'cF6-+(clNNsP66i(lH#]1OSl6B)n6sF7+isS4', '[i7si3FrF]BFF6r6l6SF-iPS6S6H6HSCs5s', '[sF27riS36]6il66Fic--7]6cirlcPc7slc', '-S26eSn1IFS7i4[6-e7rc-SHss2N-NS-2sPc6r', 'sS[nir7pS6NBSSSp667bS26IFcHSH7ol6rO[=#N', 'r[eiFePc66cnlPNibHH]]cCbrN66ce-HC76', 'ib-i#iP7iS2BFH7r-Fs(+llI46H-6F(F7B6', 'ri#l62F#F)F-#6Il6HF3l-seF6ccsSiiOs=cS', '6iieS6SSHPsI7S-6sScr6N]6FI+Oi5[+NF', 'iiCHs7i[Nc]36OH]6)6#+Hisi7i3bF6lPPc6[', '[F[r2Hl-Hc-lFP-2r-lP6INclieCicHi-i4H', 'clc-irsS6oP+s[lsi--SS#r#FcSc62piliiFH', 'Soli66]76r6F6rFPHii7#=67ii6NH--#3s-', 'eiiNPIi6FSC-[O67SF(lF6r+S-S+i-OFSS27sHsi', 'P6eSIs6FS(Ss(C3--77cSSiFNo3iF-SSI#FN#F', 'icCNioSSlcSS6616HiSSln1cH6iirlris-6e(Ii', 'IiHlrI-H-6#SFlcO2FN63c7S#-lBF]sccriSiF', 'sS7rPSsr-2rOi66sSIc2(6i(=[]Fr6712scHS', 'Ic#[i(6Fcsl6FF6oSHseli26677sSF()2s6eoS', '#[B2FFi#ie]neFrl=p[F4FSFocoCs#6O(n-+', 'e=pri[i+67n]Hi7ie66i[-ccHs5HFbi6sF4', '-B4+]-2s+s-Fc-(6l(]2iili+F]#46riS-il-ii', '6FFc(Ns-56[c-PrsbFF#66l6p521ilil6ii6i', '6N-FSF=[I2]6Nis-2s[7ii7HS-6ScB6cOS7c]2', 'Fll6ibsSlS6-4=iiil[HF-HS-cSsSi7iccF[e-', 'i)b-bBbcecc[#-O+I26-F26=#6#-iiCiCcrr', '+[ilPHb--nFbiNsFs2O[#NcPlFb26l67sIl6#S', 'SPc-lclSic262Pr+23Ci[S#scciiPp]HFbs6PFI', 'i7-2Psinc-Oii3N]7Pl6irH]-(SSs=HF#7c7Hc', '7c#lcH#cei7iFH[7lH7i6Frr62H24BlSrSs-', 'cS7]2c+Fc6n6s6#-oi6c-F6si6762HPPs', '(7#iirSr67Hc+iiPlssrC-[e26[O(7+ir6Hp=O', 'HOir6r#sIF-SlP=-2-i-HF[7#62HiicrcpN3Fr', 'cF[PSss+lo6PeF676c(7ciB-sF]lli26r-6ci', 's]oiFPFS3-6=F6c-clOi7Ce-es6(6sF=6#', '=-76i[sccs6iil6e6lsi27F6ciel=O+iSlS[6[i', '5SirHiiNirS6277iP(OlslsH-66Ci6r7s', '+s6r-7HSlSs+ic67[(6iOC6-F6e]e]ci1F#lB(', '1H66[b-3Sicss766SF(FciF6cF6-S4[bSl2H', '(s)i)4irH6s[6+lSlsi]2FPlcC26c-l6#Fi1+', 'ic7NNSSF#Ssoc--[l(2lFBbil6=l6ClI6c', 'HnCOc62Fci-l6i25+[#i2Frllsr]S6#(cBFFF6P', '6[-6+-lHHn#666Fiins-H-l-6SsPNc#HPcbillce', 'e666sseBiio[26[HsPl2iSsP7pii-Fis6is66', 'slH6-sFHi3cs2BS6H6liSIFFOFel3-Css-', '6#c-7s-iF]OFl(+6S[c-FsbBOsc7s[)[F[S[6', '#7r7lS6r2CI[Fci7CFi[l7lFHp+lb7', '-c=cc[S2iF]i=s7Hsc6SsiSiiiS-iPOciSI62o', 'eSosc--s2lS2-FH=cl)iPiCNSS6Fs6FFSs', 'lbccse1(cs-rS4ssHi=-]oH6ip6-SSiHF36][ss', '7-6isHPOiOSPSci2e6s-[c3i-HC6Fs6', '6P=l3FSPsic-#sIF6lFHHBFSn[i3c2-sl27H6', 'HrerFi2lbSN672bls1-6r6]6cI7F67Ncs4[Fs', '7SsiOFsOSiNlNC6sF-eiSl6iP6cSsF7+Fi-#', 'FbipiFCo-52HlIll-6I[l[rlsSSNH7ScSF', 'FFo66[Fsc67sP77[27S+PsiiI6r77#7r+HisS', ')Fb6F2i7Nr7licP2s-(2-BPHi=sFSH=Sl6H76r', 'Fscir+CF[F[Siil-6lslF6srcrlSso26lnp6N[[', '67pHsF74#7HHHiols#S6lS+iCS+]sOcSOcs-6c', 'cPIS7OF-7IPHcc-FHPrSBiFrF7FFSlIlbsiF', 'b6sOii62pHS-6#H7-NrSrbSSic-66s-S=(6', '6HsOsFsiSiFp6iH+-6[cH])ccP7ciicFIi', 'NHIcNlP#--c3FF-6S26]eH2)lN#-6S(Cs+s', '7S-66lFHSSliNNSPP#siHi-i3FcsFlsF-p6s#', 'rliBn(-p6FbF67=2Hl2S672ii4rI#lF+i(lcr-', '(rsC7-4F7ssHllH626IiS--6[FS-Hr6C7-', 'F6i(6FbsO2lS6]Hplc6NFSSe#-BF-bclO-r-F', 'S=SHcsBS+ncOcsFicp-+6cC#67F+OcliFl)-ii', 'F27#l6ib(iib[(Fi6H#c66Heos#FsscF[l67#', '[r6pii-#P[(c--cSS-6F[ic=H7(eI2H2llHc-6', 'cH6626])Fie66-O[642Ss6e67226F26#[Sr7c', 'eiiin6FPrF(SssFc6FC6ieb#isiS3csSlc6(', '+67-clS7cHl-6-S[27FBoli6FScI3pcl#Sli', '266-HcI-l+)[ii1FP762sC+7-F3irnir-76iili', 'SlIPSbF4672i62sSsec7-e7r-H2s-ccioibS6', '2Sbs([6+6cr](FPleBscrl6[F+lo7#2H', 'HSioF=7HBil6cS[+F#2SlH4i[PH67--S6l-l', 'HNiSs-7[i6FS4S[=i(#2+Hl7-2sFo6sliS4Sc', '2Slcii42Cci66e)67BIIF(=l62[rcs-6+-i6Fc73', '6iH56niFP16r7c(IIcHc6Pi26Nr6F[ii7SC-i', '66H6i---676HlSS6HHc=r2rHi=-Poi[PIF6i', '2--i+FFBcO-O6IHFSlli=6sol5eN7]NI67iP63', '76His(Fc#HSHb7(FB]csiPCFoFni3-lH-pcss2', '2l7--63P[s66S6PHr276p6ss-(F77426l26', 'B-6IlssFiil=7ip6OirHsSF7nSB-i6e67srcSl', '66FiriiHHs+B2F2crSclcPsOSF-c6c[p-OSF(6', '6c+i=Ssir6oSSSH+ri7SSHsSiPsiss#ScssS6', 'Fc2S6i77SliiI6liF72-C#P)2spF#-ii6lc', '(sSroc+l6l2F=7i[cl674ii77FiFc=SsFO2H(F-', '26c+ll=]pic45c[r66cOi+s-lir]rP2S6ci#i#S', 'Fc6[i6F[2N-FHF+l2i3l#6FH7s6-66HlcS6c2F', 'SN+s6llSH56i(#i6F76F6S-C66C+scl]Fic-26i', 'lBFF[iiSpil2FS7cp6i6FcFc26r6i2sc(ciiS', '(sS7--si7Fr-HHPF=iHH--cHs-l+rP26OFFrn', 'p-rF6#FFlF#-i5Pi666rcS6]4I6lcPIHs26', '7i7PllS6C7Fin6O-[FN2s6li7FPeC6-HHl-[7', 'sHslNii7c([s-i]-467n#iSH-c6e]l3S=H(H-i(', 'SF(Pp2=cisOslii5]S6lcslSli7H-e]-c[c+c#S', ')ll-7l32+]N(ci26#s-reHics6[NbHl+HiS-(Nc', '-S7SHF(2-77-eNi#Fssl#Ie]s]--SlbSlS6i[S', '[e]+slPcbic=6iiPlS52iiHi36HsScSPN7-c6-H', 'bCF3Hi]-F4sFi-l]Hcri-OSrP-NSiFFSsSFN', 'iclcF7rCissiSrF#=l-iH-7icli#2p+c[6HN-s', '6i7#FrF6P646sH676ciiF=+-2[-6cc2-rbS[2O', 's-e)l6HOri(S6#Oiii67FS6HS6l2#6+c[cl2', '7cS+i#S64[c[s#S+7lSl[biieHI-s6F[7SIi-', 'lscc-S2Ni2sF(2+ll=6[ic71c66-#s]pi#ce', '6-7Fi7s[e6i[pH[-6#(-s76son]li+6blcnH6', 'C-i#S6[FnFFr[=OsSeS)-FSCP7c-F2e2SHsS[ciP', '6Fll6SiSs-s-rFbe#]-iSiF12[67PpS[iPP#SH', 'S7r]s66SF+i=sScs+c7i72i6i1[clHS7[INs', 'cc66-cH6cF-e6irHlFSeSs6l[IPsPPnNpSl6', '2i-#[i3-l2iii=FllllsSSirSFi+6ir7]Sib6lO6', '+(FcF6F+26iHS-rB-Nsr[FilPls-ieSHNel=', '26[S=liiciiPo(ciH+P6ii(6sHPr#[e#Fc+F(', '7FH-rNrNF=2sS1P6sC6ibS+6ibcH(F[SFOi-', '(+s7=r6ii+H[pF[liF7Fe[NS+6e66[FSl2sn-]S', 'ePNH#Hlcpl-6lPHbiF4]ccHilPIS6iF(c#+FP', '-srplSs-ii66ssNi[N+iPi6-6SF2Fc7c-5S', ']Fs[c(-F(iseFclSF6=l-elcsc]#cisi+7', 'FSHSrlicci7c#6FiFC]SS=#Fic+-6rFrn7-#i', 'i6H6s=S#ccF6-p-I2HS#s#FbSIHH--6c6F', '7Ficilr3(Si76Hil[#7#iiic66[r-iNs-66Pil', 'INOssFPFO+2rF33eFii#NicF7HI-[[76r', '66IF76Fsein7Hln[6H)oiPi#rc)276-c-6S', '6-HP5s+2HccBFNo+l66716l]2FF]r6SS=7FpH', 'Si1Si[#Ni-N-issc#+FS7iF-[F=c]-riH+SbP', ']7Oi6S-6eisI66Hl[Or#S-66]SSs5iio#6#b', 'NFb+F6FilHFsS-(Fr=rPHc6iFeci-r62s[iH', 'r+F-5#i+iC=[5==Oi[FSscIlFSir2rSIFFS2(', 'Fil6C(+SBs16cc6Src-22F]67sl67lFi-6ciF-', '=7N#-77lrS6F(7F6)i-6enllSSrls4iiHi]li-P', '[e2S-osNc6iHss6IB6-66N(6[6O77eo-lHs7rc', 'SsSS2rF7Se(66c7I-l]2sn]-sFs2riF-Pr[6H++i', 'HIPi(NS7ccSrcHS#F6c2cF]#SiPrFSpF66r66', '(Fe6FSiPi6rF)i2HsSiP]FrrSFc46]76cB[o', 'FNs-HeFFr67rcF#FCieciSS77SlSrl67i+', 'Ss6s-P6F(7ii7OsF7-rsIS6nB+(6S6le3i-c+', '77Fn6H6F(I([66eF#6]c2cIlN]c]siI4#Ss', '-nBiH6-S-sHF6lsFF#ib675PS6rlc6iiNr[i', 'F]cF]6PHnp67-S-S5lF6lIiel2rHsr[7S6IlcsF', ']6F[7s67lP(1[-Hp1oOCscH+5BccisI6iiscS-', 'rrS#lS67F=##-lb26-sc2Hc67i(2l66N)#SriN', 'oc2I=6sl6726-6ii26pco76[bci6l6F]br[ir2', 'FNNbFS2-7i4nBS72ibo-lccCi-sl#N6I6ii6I6', '6]HHcFNOllP7Hlii5FIsF7P6s2rH[#i656#S+S', '+=c#c67li=SiiBi26cFsiIsl66l6F2clPlr', '6-rF3S7S#SirrbScll567sHiil#iFceFF-F2S', 'F=6Si46FS#sF[-HFSs-sOHiC-2Il6s76Oci++i', 'e6FP66=ioesSp(S6Si2Hs776lNl6PI-46FClN', ')(c)626bs6-lIFHcs(HcN6liSFrHi7iSlc6-css', 'FF-Hi7SS#s]FH6SSlS#7FNBSi26liCFS7#4c7', 'OFn-Isb--FCPHbr+i6-BFnPIF6(lHiSi7', 'iSl2l6i6oP56FSPI6lSiscFs6ciNPis--FP', 'so22Poliii]FlIsSbs2iP6FiNoHl(#SssOs6FN', 'iiHNcb-6Fn6irlsS-iFi3ciF[rHP[s6icO-S-H', '#lci66sFls-5i4N-6HH7H-s[N6-F36r622FB77', ')SP6scF+66Hsi7+lP[sSsO-l+iiSl66in[lsI', 'e(#s#s+cl6c-lC7isl[cc7sF7276[S62[r]', 'c[[lF])4[]Pcsl[iON62iSS+6S76F(7F#6-7', '+PFS677+n#76lsrcieFs66]+66S[-icF6l', 'Ss26O-eclFHli46S6]i--S#-P6F=r6F[IssNc6eF', 'i+677rFNSlcF#62el=PPcssco66)c6lr6F6H]26', ']lciPb6i#6FiO(7+NSHss-cc2pcFc+scP-Fo2', '+2F3pHHF(b7i6oSll(pHsSSr-FFS6lBi(7H-cO', 'einHSr4H66-lFsSsO-OSsBF#i6nreb#icssSI', 'F#22seHF3Nsl(ccie(FSi]FN-27i5#FNs2S6P', '-Pincsi[-2[r[=F6lcic=S2cl+cBi6[s-lS-]', 'c76i(6cF(46PlFNFNi-6lH-SSHnrF3rc7rNF', 'N[26sB16Cs[iCPclNcO-6[Fsc6r(l67ii+r-7c', ']lsSIi-6--P--6cclP[[7SlF+Hl]2r6+-]F', 'cN-i6cPF6NF[cSSS27+(]c=Sl[[Sl6CHli7HF', 'F3]lI(SSslF[62r]coi66si-c=lc+F36F', 'e+l6-672ioSpcl-iHc2lsFi67ic26+Fbo', '7iIl][iP6N6Pli#i#rl=scbS+67[sS=c[rlN', 'F2sN]#SSl-F4Ss6iii6S6F67cccSH72+cF]', 'OciS6i#i+o[c6P6s7p6([77ilISiFi6I]i7H6', 'c--SrF#6sl67-s-SOIc-6lcl62NNcs)-7)H', 'r26cr-ciHs6SsI[--l6]-sHsnNF-SF1i(Fl7', 'I[-4-#Hnr-psFlss-rNils=67lcii(i-H7S-H', 'nF6c-scS#FSF==BHisnc-HH47ls6rSs6riPib2', 'BFF6r]7ISFi4SF#Fl-irl6lFFFC2-r676-c-SH6r', 'Si26c6NSsF(HiCF77r626ssBP#-(csHFib67-', 'l32sr47cl2s7FFccipi-#[srcPeCr-FcSS6]SF', '+6c+sSs7P3iN6#Hbn[Cic+C-O#si4cHi#I6-]', '(rs-6iFsO62sO)6---ObHcCllS7ScSi#oNsc-HHo', 'rH6FslFSsscl+cs[SHsSBF6ss[i62cl2Sslc', 'l3Fpbse]r6F1ls+666cSiei6S-Ncss[irl-5r', 'cIil6Hi6Fii36#6(-6rsii77IS#F23BSsl-sl6l', 'H7[FSs+cci6rlr=re]ccblci=[[ps]6ScH', 'l2sSlII2F4[i3F26-6F7HF[)H6-FSHsln6Fi6sO', '-3lSFl[iFNS6Is-OlH[6P)lS#7NsslSr-bFb', 'isPCi6lSspOsl2[-cS6F2NIs6P66HSl)iFS6', 'l6Hi2sFrP62-O-nc265S(66-6S6Fi-Sri(r3++', 'O(]2#NHiiP6#BsPiSlls6767i22I224c-7--=', 'p6P#SI26F6cFSlrS26-i-HFlSi6-F=46FB2i6', 'r6(HsSP+I+26CF=bcIiPFcs6rcrS-=S+ls2[66#', '-+Pr666b6clF6lFbriF#c+l6cIF#cs6-+ir6S', 'SiF2(2I6rlcSiFb76Hsr7c-6r7[r-6cP-H2PCii', 'Hs-n#r-S#Sp7sO26cii#sFP-i-6[-ss+6lH', 'rHnp2+cSHF=Slccc6s[-ssFHl56oSF6-cc76', 'SSSiC7H[SFccIi]FF[isH-2piei2lHliH6liibb', '72F7S672s-Si6--FiFi4icFl6rNPS67-S', 'O6cisHs-6+cii-HHieSlS76Pl21Bis76r-Bi2', '26[cH77i[=cFCSic26HBIbF-#6rS6ei#6PproHs', 'SSi6Pi6(ss7-[3#ii6csP(SFcSicSiPp-+lS]2', '56HSSS76+c]b#HSo#il6-r]ccFIccs6#Ol6', 'e][F]BpiS7Cr#i6-]-Iire#s6F-176)#2I6IF', 'll6iH]Nc]-e#Iciir]c2iieS6el(F2SF=i]eHs', 'r-66ccspcceF4sFNiFiHsH67He[-Oi]cO76e', 's7F[p27i+irFSiccc[2ebSSl2(N-7+HScHc6', '6sS6rii6-i67SC-[=BOiF2sii##26+HFcHi', 'b6c(FS66-p276ls6r7lcbc6FH6Nie[Hsc-i6H6', 'e2p[sS-SH7S7sciBb1=i7SFclccir]rHSr2H', '2n6Hs[e+IFNH6FF67ii6IPSS[#B-SH-csn', 'Occ6PcCiicssr2e-s-OBl2H=I2lHsi6[bc76s', '7[r+[==-S=-iSlS-HcecFNNS-[6lle][6FnF', '26ip7iiSS-Iis#c6i1ll(isSH6cl+n(lH6S[iSS', 'i7F27l6[F6cHsF[7F6rcii2rSiO6FoFs+FHcii', 'Hi4lo+#-F+=c-Po67rc]BiHOFIiS6Sc7iSr', 'ir63+7cH(+HsSFBF(sHlsl4i3OFi-7[)7rFB', '#6-7icBrS7-2)Or]l[)6-i]OF7c-2SO-sHiOl)lc', '6F-]7+4S6I6iSc[N-(6FNlSSl7Si6p6F]iFSF', 'Fr7s+l6i5SS(#l6N#7csFHeolPccS2p[[-ic2cs', '26er]ccF4iiH=icS=4-66#eH-Nr7-ci[c6s6', '6biF[2-OcOSc3FSSHbs[6H[#lBFrF2(6757ii', '7icOsN6#6#P6[#Nc-HHPlso677ee[s+e6bFIcNc', '6ciciOHs6S-6(12iSS#iS6ri#SseN2PiSFccHHF', '(=i66c)ScNBSiHPcp-i(io6Oo=Obe6FOl-C6ri', '[ci7FNF123b6-7iS66]b3772r6lcc-FFPSl', '6r+(r+FrFFSis-F+FFcs[=7-iO-reIBii26[cc', 'HcSHpsSrlFF-pl+iNcc32CFH]nF+6iFibs-S', ')N-lr66N)]6[i-+cNF6F66F66p6667FFF6]6ll', 'rs[HP6icP=SciFFp[Si2-3S6FFlHsS2sei', 'ibSiiN67-l-+SHiF6srcFi3lllF(2sc67r2', '26sS7[26Ss66N6ic3i26F#67c6F6cP12B6lB3i', 'F66F=46sseP6-P6c-[iO6]S6C6F+cS2Hs=+2io6', 'cHo]66FP#SI26cc#+7H-S[S6]267Hs7iirH]2F', 'l5cr2S)7i7s4F#2rbsFb2eFHs7rolP6c6S6FF]r', ')+i663IP[7eI27rs[ilOiHln2iic6FF2rccsSH', 'r2F[s7p)bF#cc2F-r+lsc3H-FCcOF7iFnFFNl', 'l2rHsS(oF+nls-6Hi-ics62c#ic6#6[6Sr6c6', 'rlF2-3i6N+Bi6r)6-oSs7(c[4S+c]-ll6li2r', 'i6bl6c3clccciiNbics4bilSoFii-6', 'i(26H7iNsie#ieH-l-6r67rNCSS57FSFI6667(', '6(l(]2FF6FB62672SHsF[s-S[[=psr]is6F2', 'ss6c[c-4oF#l6P-iPic6FS7l[72N#7i6S=i2', '26c27[lcIFc=c-rcer6l77F]HHiNnrHi-B]PsH-#', '6c27l[C676c336iH4eS6[i-(F6Ib6c6[l2Hi)7', '26Hr232H3)F[--SHHSFF66FS(2spsi[sOS676', 'iCF(i6i2FirH67]l7s7+e26i6pSH7iHsi6#6', '6F6Nc]3psrP67iHresibc+7Ni67cFF#2[r+cS', '-FiOll7r-HSPl6iceS-s16l6F6-+FNSr7bcS', 'SlSHi7H)66sol-Hsc2O6ilcSSH#(l6lrFPP7S', 'n]#F6F46-liIiiPI6F7SPsB6s6cliF46IFcic', 'I2eneH7SF3p-r6F6[-F6S6o6Frlc66l26F', 'lcc(6-7e2bH[-i6r6l66iF[s6[#--e6IioI(', 'e+iiiPl+eeSH7ilBPl]H2667H6eFCNF=FH[-6i6', 'r[piS]=6cS7+c67cbrIlSHcH+SFrH-B[i]-6r', 'rPcli7H46#scs6cecbp6IsS-s6Fciibr', 's+-Fp#SsPBi#ec6(c6oF6FSiii-6rObi(so', '-F6i(-[+Ii6l=nrc66-FIcoiP6cBlp6FHs2', 'H-46-FIS6Hl(S]Sl6eFNcS(SP26)r6[6IBS#r', 'l6c-SSo26-FSI-+o7H76e2cS=H6I(#Hlii2[F', '7oSS7FrccHS62H+icS2i6I[(iec[6]lsi(+)Npc', 'SS662Fic67i2S=l63rF6]H2Sos-7eNiii-]6lS-', '+6Fc2rsi(iOSPoFp7+l62rSlFo7i-]27er', '#6iFS6#ccHSISr67i6erl6]cSF-6IciNb67]ib[', 'llc-FN[-H=SiSicr6sH(6#7-ii=FH-67s+Oo', 'l6=cHHHci-(li+Hiie7+SSBl=i[croHiF#b6esF7', '66[si4#]]cPcsHsl(ii-#i##spHP#iFlrF2eFS7(', '26FHc(SF#O66Hi#ii6-sl6FiOiriFccl[6i', 'F72s6#2r+]7-2Ic--s66+S7lSis6Fi76C-', ']7HssslHIeriP2Hri--F6-H+[3i=F+il6#]', '-Sc6-eS+(sCB2ie2s-6CcSr6Si2pSs#BFnr', 'rlbrl6[s-c2F4-Si16S+oHc-O-l-NssSrcin[o', 'rB6#B[Nice#r[FIS7-#2rN7FrPs+i3F76', 'S7+6nS)sH5[c2NcSH7iFN+l6c5r6Ii2n66B2Be#', 'ccHsFH6br=Obi6i]ss3[r-pNF7##cPr2Ie+7', 'icis[b26l66rr666ioIsS4(sesic=s6sccse2HN', '7SiSri-#6i3-F2=s636Co6H-Fs[-S-c=+-s', 'l(SHnS[F]FHIFlciHlnHFlo67(S66bS2iS1', 'iiip6FlirisrbFSSe6-l(F##6rs6sr6coH-7FcS6', '6Fn-ScisS6FH[Is+66Fl(FFbFBHHi6sPr2c6-', '2bFBil2SlN-F6SHeil6FS#]6[77F1[i466', 'H)2rHsSs-=2lFr2e6I#Iisr7l=6[F(7FP6', '[6-[SOF#64cF3cr[i+-cPS7cFSib-666[6rcS', 'eP6icF6iSSH+6ccei(6icS7-7I6]F6r-H26', '[ieop7cssSI664SOc+pFn[SSHi2HHlr6P', '(enH-6]-l6=+SS6Fr7FS+H2H)P-lbil62F6HH', 'S#]S-+HS67pl6SHH7B(#ilcC[s(#l6#ii67Fi+Fn', '2FPnSSF]lHiF7i7e2-6pii3I67i76s(cH[i#e', 'b]36[S-7FH6(rcFirclIs)62HcSrNFHsc', '6rbp-2sFe-FcOl+ISii4-2HFC6cF-6OS2c6N#Fi', 'Ici377c57-NHi27S6F[FHsHPSiiePrs-Sr7s2', 's-S6e7rclOs-Ic-#FiircrSF#sFFF6H6HIiSS', 'S-lssi2lF]Hl6r]eSl6F6-is[S-O--F=iNssH', 'lPH#-(F67i(iHSS-(l6Hc+il6iFns-slii', 'H6FP(c-ci6Hsp-5#SIsccs-icFHbF(FSs#(CI', 'e=H47Icl6S6FFci]FFrscr]7OlsH#cr[#F672r', 'F-=i-[siNF-)3pcpHc6s6[7il2I4-][sii=ii', '-s67Ns[Pii7Bs6B6Oli67c3F7Si#cc6Hcici2', 'nF3]FHS[IN6csFPleP7c+iS7i=4i]F6SIrsrp7ic', '#-PolIiHls-66-iFi7e]2B-eo6PcC[6siO', '-i]Sr(iOcHcN-F2=2P]i6p[-iesc636pliCcH', '[Or+cscHS6HFil66s2F6rPp6ciSi-sc(FFb', 'iP[-7oiIO-r6SFsei-BrFs+lsHiO2p7P6H66i', 'iS5[Fc6ieoiip2FsHir2HBHiiHiiccs#2r#=6', '72eiP6F7c2H-2-rrH6#CPPl6S7cH26l)-ir6', 'sSI6FSsiFiS7lH66FP-6Fe6b+i(l6HiS6#or', '2e67HFsoI272SlC[HlFlrliHiii-rSH3s+lb-', 'iOF#s+6cF+HiSF(=[PFS5+7Ic6iir+i-rFe-F', '7rO-e6HH-(16-6Fl16-I-S6i-sISOlncH[IFH', 'l2SSe(OHOsce56ier6[(BFC-)67F6ilS22Sc2', 'lP(7-SF2lOFbHiF6-i-(7S=ibl[cFHi+C#37', 'cP66ibo=7(-+l(cic(6OSlsSpBl-6P+l[cs)c6', 'ss#l2sP6eFii6cF2rsisp+ssFi6r6IFr-pF26', 'cS+2iIr7[csl--72rlF#pHclcH=IS7-=]isC6', '76eSP#+7Fi(SS+cl-]]]6sl6#b=673csSrc6r66', 'Oc26+6pH=P-sSFii6Fr-s6[cBcFseFP6S(oli7l', '+nci-O62cFi=S66FlcbB6IFs-656F2[sS#isbB-', 'slIiFi7273cs--3ceSsccOPF+SSFF[=7rIr', 'bse6liCBii+=((=N#iiSC]=l6iN2r67l-62=N6', 'c=FIOFSS]ii#o2Hl6FcHN67l26r[l666c27i7', '7-SH6NFSS+[icFNii2F#p(Hi(ll3s[+nSs7c', 'e47ri-sHcH-Il2i-s-sP+6#eiHP6P-H[2s5', ']lli#6c4-7(SOc+CP6-6ii6)[6r-ep6HHe2', 'll62o#6F+csc2sc6BO6FF#Pi6Hss-77F6-HHl#C', '-Ssc6oiSr#]F(o]F#i6clS-(S7Bs-27si5C', 'ciS]-6Nc6cF-P6Icce72F]-Hii6lsri+iH', 'rri]]P-PlHisiFnIlscHSSis7FIii-c6i7C6]l', 'iiec)ii6cl-iiepiiI]6c=Pp6-cP7267Hi', 'iOB6[ilH[ssS5-6c6i6csS-iSc4-lNO#SF2[ic', '[#6Fr)6[2F7SS[#+sc-siBHbS-s6#ls2(-Hc', 'Si[6-SiHS3s67IiPl7llP#siFS]s6]2i#SSii', 'S7C-5C6]PolHe6CHnS6[P6HS+[H[r-==#((6Fi', 'i6p-cclS76nH2iCNi-lFiPcS-ls7F67-eSr', 'l7H-c6[IniHcS6Ssn7l6oF[Hcii#slc-ise)[', '+ic726F-7cHCscS2ISls#ip2icNH]767[FNi(', 'sSpF#7N2ii6SN[7c+7+lSii2i6cco#6#F4N2c', '7B-c-F[67IsF(l=7)c76H-i4crcl62B6eCr', '67NNr3rsiSc26S676ciN4O(-n1r6[6FS+Fr[', 'c(6FbHSH66HeF4e-l6[F+-SH]iHHS62PScP[F-li', 'HFHiP2F#sH7i-4S-sPB[c-il6FFlrci[s', '7b2lS7FFcS[F-rScisciF#-SFHSc6sFn6cs)-6', 'ssH[ii[IH-H3c6S-O6HHi5e6pic6--e]sF23', 'bpri6Fr[66cP7il6c=BSeClS7ii-IelOiPS7', 'SoPlBsiISsclo#F-7[7i-ll-i2HOSPlIes-l', 'ie67cH6-2nbO]i5iFF[pcc-(6i(SCbr-F-iee', 'sI-6l=]6srlOs+cI6SH6#H)SiisiI[6]6rcObSc', 'ci=lFr)HO66Fe22OS72i7+SpF-iF3(slb6', 'rlcrie2rFNi3r+iPc6672SH6i[sFFB26li6P', 'rlP7]6csFH5scl6F7ii6FsH27P-(crrFrS#FF', '2l6Hl[-[i#Fc-S6--i=c2##56Fr-PN-+c(', '72licB]cOpscFl=S#F#P6rFNOiFPI#i-i=s6H', 'rS7BCs--rliFb72SsFS#lB2He26c27FlNlpF', 'CPS6O273-c66oir2lbllF2is-escHicF+i-ciF', '766C]i]2r67ssSlS=r]2]O-S-S)Fci-6rIiF-ir', '2-HibO[-6SbBrcPlSNF[[lbn]csF77(Fici6', '+F]-S3b(c+6il-PSc36lieo-o)IpS=sSS6i=B7iF', 'SSHsicsr7Nis[P6)i66-i-s-(C-ns-+6sbP6e', 'cc47ss-FS666FiSF1l-FF#i4=]Sic(76P[', 'SipSlciF7NCFNI2SssOls6eH(lr-+FciiI6]', 'PF72Bss]c-6elc6cP=Ni(is2iFOliliSsH4', '(]oc6-6lS+2==iliP7lB56s7166Fisi-[Sir6', '#O6S-H-I66PFHB1H]-+FFcs-i-6FI6-726#c', 'i6i#S=7sN[b7FBs67[b[iPl-r6c6i6Flr7=SFO', '6l6siFF7OHiFH6P-iSB3blscs2HHici2iOOPlF-(', 'H7esilI4S-66i6rScc-s-FI#2IlrccsclcI6I', 'FNiSsi6[iCSBSFocOcs-6FH+s62s6ccHcC3lI[6', 'HsHilrr6-sS-O6isoHSi6P#riP3c]iH-l2Hl3S7', ']FsbsFSlsccco-6-=iSi67ceF77)Feb-P[l61P6', 'lHic[66PsSe-p6F6IsicinH-SsFS7[FPFc', '6elcs#c-67HIn-5c=HrP66]-c]FsSHiFbP', '7[2r6F(Fri(ir+i)CccicirCs(oc6Hii)1F', '-(PcoiiSSl-7O7i7siic6ce6ollie]isPFs6#i=', 'e6+iFN7r]6F7F[cSFNiFH)7c6HrSs6r6-lF7H', 'sHlsHls6-r6PI+l76IpF6s-2F[iOiFii6SS', '766l6rSs+lF7lHH(ri667sFi66l26l66OFl', 'll6)-cHn7S-7iS(s-iF22iPBIi6O[#6osI#', '75N6llScP=Pl=[5p+[r6iSNc6ircs]pisc77II', ']sFrcci66i7il]iFsSscsO2-ceFNcN=FSSi', 'i[s-6li7sl3+2Fs61is7FlFpHI2OpoFBc+b-F', 'IS2sF#2B[s(c(Fsii]BSbiF2-eN6cssr76]6r', 'r6r-6sibO3]##2siiF2SiP[cs7-6i667]cI3-+in', '6lcl6lci6i)FincIoIs7e6HI6H-p2r6r6SlNi', 'S7##css6FelHs+cccs6P[iSisFF(ss2rSc', 'IC6-p7Fni6ciF6=iic-2772SbnFoS-6l-O2s+i', '2rSIi7-Pe-2[+Icls-rcsn1-FNsFicc2H6-F6', 'SIicb6I]7FlFSi##F-F[s7iiS7lSe)ci=B6', '7c66F6iF6c+Pbssi2=Pibp[4Si2Ii42r2F[i', '6S-6-i47S6iP36]6--F6FFi=FC6FS27iSscSb', 'F7Hls-31S6][7FSb3sioliPHHnS#i(6FiiiOSSl', 'n=siCcFb3[i6-#(F-r6=iON6cc=6FSclcS6s', 'si676-F3O)7FeiIcFl-l6c-7+6l#-7sOB6FH-O', '[HB-HCBHcs-i7-[[Oi]FpiOrrFFiSS+[-eocc-', 'N7ncisPiBbF]SiSS26bip6l7lrl6F673S[iiFN', 'i+Or]lScIN]i-s2s-p66cI-lcr[S6P53i(ci6s(', 'SHlP6ic6Fn3Is62FHS2li6HHc-6Hi-66nl26', 'HslIFSc66rlIcs-O2[24rFlS-S+iH]N6SH', '66-iF]C6FSipbr6el2pHsSl-S-SisSi[-6SIs6', 'SHssHF7HHSsssc#6FFr-6OHH6H=76e(77r', '6FcSlSF#764Hc6F6IS[i77bBB+SiiCisrC[6p6-H', 'lSF67e6r+ls2Cc6iS2[i#]HsPPSSsc#', '2PHnF2S6SSr-crH7s2i+5#)r6riFN2iibip7ccI', 'ccicso4[b6+cipNI6sisccp6r[sNSssF]HSS', '#[-Ces+ssp2Scs67cIlHsSsO=F(l6FI77r+Si]c', '-4i6r[sS#iiO-6lSi(e[6OCF#s-=i6FcS26', 'F7o-4]FO6-6lnr6F[l6cbesP16]-cIoFS6s', 'Se#--F-BOS+[=c+HCFelr+-S[l6ci)6i[NH', 'ciS6lclS6F-o2H]FlP6667)76ii[HcBic+bF-H', 'S6ccS26]-I7F7-46OO3[r6l6il-7icSo64+l', '(-7cS#Sc2Fercs6bHPl7#HF7FcO)Pi6lF6i', '[-S667i67iCrli[eI[6il6[clseS6+3IFoSF6', 'i3+SN=iciHPi+iO-SS6iF7PC6i2F(Sssr7', '6Il-PPF+2rFO6SF[rcFe[i]ol6FiFclie76', 'OIlciFNc]rc-2s67celI]ieS]6ics(cl7-ir', '[rSS-6HP-sHHi#Fi-(F2cli[Sr2[i-H6Iip-rn', '6CIH6P=6#cc6#C7#-SS6ro[i676]2S[+7p6F', 'FIS6#r722sS[I7cSi[3oS-Fen-666e2i1HS#nS', '6]6NbObHcl6[67slicp6c(S2F7il66)iss]-i', 'I]ceH2s)c6#7r[Hlc6[cHFF6iisOi5[+P', 's2Ss6P2ni6SSF(766i3bSFibI72c-Ss[sFO-H2', '[is6S7c]eF-Pci5[co6-6[F7ie#iisiFFr5[[', '+FeN-6Nrs2HPSFFI26+I6i[ic+ibP6scnri#sH', 'b-2ss2SF23l266cl7-]-e6lrls(b-lss6IH6rHH', 'eS726cc+[PcP66Hs646[-eIrS+sFSFlH66ccN', '-rN2bSr-HH626riFF77lF3l-O=pcsl6PH5-', 'si62SS6#o-(i=2lIiciHlIcFl6ls-7HsC2[7r', ']c[FIriNsF6e6FcHSOF6rFO7HP6(Ii-scc6i', 'IPs#2--FNsr67S(6=P66cc6sp]F2=HS#Fss-6', 'l7]7lH6#Fic6IF2p6i6-F2licbFlcp+(7ci1(Hn', '267c(ii6#biBiP#S6[crF[#[ibSlIbl7246I', 'ii4siis+ccSs2riHBH]]SHO7o(iO7n72=c6', 'H-Fl#Si67oSs7N])-Hs[liiHc6SSpnic', '(ssS3iHSFSFOiHHlcI6[6c74cIli-PF776i', 's#Hs6F1OF-c67ciS267iiF72F-OiS6H6crs6l', '#62=2[6sccis3Ir[pF]r+(6l6S6N5sO[F-li', 'FrS-F66cSiS26sH76S--7Hc[+lc+-+Ss)]OiSF6', 'n-6i6i#66lc6i]cI[6I6Ppi]FbFibeS6-6CP-', '2F6FilF-#Fin3r]6nbSP6l7cbSi4eI4s--(SH', 'iB-6s-6FbFF]rPclsioSHsiC666i6sBHb77c', '67)BF276]icFHSliiiPii(22ibc4OH-2l', 'iOI-FN7=Si(2+Pi6liP2rs6S77rSr67FlP', 'F61Hnr7i#-7iFS2OFSH6-6cs7iBF]iIC26F[', '#c7PP6lo=[i6FISFs76oHFSeSCc7c[-S5nScOFP', 'ccCi6sisic-6S=F+(icH2Hi777F6Fpilcils', 'FSH(S#7eF7HsFlB-6s67[2e2S+6lnF[sS-[', 'Hs6F(S62sccs+#ciicc-sl677O2Ho7+5H5H77', '#e6FrIi]Psii-F36eb667ibFisH=OF[-6csFN', 'FHS7iF]F7l-B7e6Bll626Fil=66O-[ic+7iSrS', 'H7ioci6F[Sc(c26lH]ll7S6]cFF3s-+HciC#ilF', '2SP6P]-ibllcOIFPF(b-6-2iSHSSPiF]Fil', '4(iiPNrSsips]csl6ci#cs#-Np7(SBi67ib-', 'Hs[H7b[H-l6oH[FiSpFc+cSPsO-(s-+iN672S', '6l6-cFNFbo[7cinrB3F2rcH=]-[Fc[#iSPlHF', '+i+Pc6i+#PSSs67-I-SeFoiNicSs(FSsn6#n', 's=cic7cNHSF[FlFi-6Hii-Fp+FSsscNPc2c', 'l[l[cSsNs#Si-Fsc-67FFc6H--727nFii5r-5]', 'ie(2[6Fs-Nr6Si-6p3]6erP7e)6celc#Fi7F#N6', ']i2sSFN=767F-7is-F7F7F6lS66-siHe]siSF', '6PI66icsFOrsS#S6(p6IF6S6i-SlHr637F#', '[(3i5Hs26cSN-7FN77[bFcSS(+n6HSe3-lSi', 'P=SssiblF3#Ier67bpi6cSl(#c-N4+SF6ci#', 'Si-s+lH[(ii6eri-#oi7ip]c67+)6H-s[sF6r', '7-i6HIFiiFSOibiOHSHi6#l-B+IcFF]-6SS-2=', '-F]c7i]B6]=N4Sr35F4i2iCi[F(#6-+6S#)12', '1[#-P[r]=2iiC-2i64Fc1iHc#I2F-l6FHi2N=#', '[F-Si72iNsH-HFN6BNHcsiis2Sii#6N-i##H', 'l+r-rF]-S6I6sesF2s6FNHS=i+-Flsnr6FNc#', 'SIicsii(cFrFcBp2S-#72cclI7(cH4PCi7iOS7i', 'nbsPi(He-PFo7Cll6elsNrerI2H-isO6i7', 'Sir=i6l(7SF+sloH[r(F-opHc6-+N7=N6SrN', '2ro66pH6BF+F6)266Fsrs77+IHcc+Hi-ibl', 'PiiI-7s+pP6Cls27[SH#SS=]-6ris+=H67ii', '7r+67l-7lrcicb2IIPi]S-22SH67slSib-c#', 'F2FlOii+Hi6e2-ipHC6#6FIiHBc6HFsF4S6HP', 'BBFHi-iI-S7NOiC76c7-s+ccs3N-cOSBFoii', 'SHns7ls-e7iF7(riFScsS6rbs6-2eF7PicO-()', 'r7s-6i1Fi#7r-iOS(FS7clSIFiirS#SBNFF', 'Bc-coS#src2siFsFn-S7r+s-6]66-[ilI[6F]3i', '6-n]S-SSS-6e[-Sipis6S[7IIF2Nc=6rolB[6', 'ci7-s)cSOPIlsc#6e-elPsSiNNN6ic#lis2c', 'F21iFSS6[c[c-[7SiiFFncl-27i67iN(e6', 's2F3ccc-IPi-iPHISN-Fo6[=(li6Pci-#rs', 'HI67H7S#2rlsSHS-sS#6H6c6[S-]i6slFi666', 'isccH=Src6sHF(H6H6IFl6O-6Fb6767]FHo', ']iiiFcsSFsOS76crcc6H7s4Sl7i+--[Ic6-I', 'lc#sr7H24-erF+2sil#ebPF1cP2is6P6iO6Ic-', 'FcIrsB=#s+6i=6267HPBi6lFiP62-[c-4[cF', 'r6577lSB#4H+ls26F6(FSp6F3+NSHBc)eSB6i', '[sSlieoi6S]HsllcSlSs+F2ieP7FFnPSi72NF', 'cHrsFN6s6#7ic#clrPc]SoCc-NSFs2BcH)-', 'FFF=F476ecreFise(S2PHSP6IIe26--F63#', 'eHHPiHccSiSS[S6FsFSSl6Hi-[r6-ie2Hsi6IS', 'lPb[[Fciscl6P66rF-i7SHFH6Hi63Ss-6re[', 'ri76B-rF6liN)ci#i6F-SlNsHC2r-6HSHc[', 'IFi]pl6cS5S2Hi+2H]6PF(6c]6SSc[F6eB[FNF', '-li#sHFc=BFesreplbFb-SHicSH6-=o[==6c', 'i6Fc6#6PFeF-ccN+OP#cFcOH-=CHHcF(P67FF', 'H627cs(ceFFFHH6c26F[iIrirHNlsO-e6#', '-F[=+6iSHl6FSs6IF]6FHcsl6HSPl6SS2sFb', 'ipF6-pSrS6i7=lHlHii#F(-+-bcPsscpFrSi', 'icH7FsliFH7PbB2sc4Bc2HSSFo#ClS5+s+6F', 'C-6+=6iS26r[S6i5PS7[l#HbpF6[4l#]26sS', '6r7i[#cIiicS(#6[7OO---[+627P7Hc(oN+cc', 'OcOSSSnHFri2c+l[#lFB77cr[rl6iNe6lolSs', '-s6lO67F2]n-lS2Frr66SH-p7Sc-iSsic#2l6FC', 'S[cc6sc-2P6H-267is((F(cF[#6OrF[S2l2Sc', 'S7iSiH4SS)iIe-7cCili5cNiclFrNF23lNcbF27H', '2rBFP+r[6F2sOs6Fs-s(6HF7lHsPHie+HHrF-', 'N7ic6FcBcr77-cSls#H+blC37c+FSHSS#l#i-H', ']SlF2HOHS-pii6cS+6pF-+6nOiOH6rroIP#F2Ni4', '7HHiPSlIS6#SiicibiH47F-H6+62rOis-iIsl)', 'ib-l72pFiFp#siS4#c]ccSO6I[+ciHio6FiiC', '7ie7#rcl(sFirOb-74s-s[](#-io7+r27c667', 'HHPPrreFrPNSS-PP676PC-Hi6FFHH6#5[[Ics', '6+SnHii-]cS-ssi6plOcicHi+i6FiilisHSlsi', '-S4H-ic+cSSHsIicll67](iosS[O6HSiSi5]', '4-HiN-ilcslI-isPl26-pbSrNc6rrH6F=-Sl', '#-#-FCcH#Fs[sBFlli(1s62--c2Finr--i2=', '6sOl2-b(S]2lbHSs5pirciF=I=rc1l+6rcH', 'cP2HHrFr4cbFHs+iPlll-b6SFNc#sSsNSii-2ri', '2s66ccHCi+Hi-li[c(iip6ScsiFlciie]i7PscH[', 'FF(ic[H)i7SF-Fier+-sSsHHC[=ib267=S66cP-', '7-eir]cH)2[6P6FSF+17sl6-eF]s-]6[lioHi', '#i7]2r[SrbPF-7HSsS+oHSIcrcISSFPsC66P#c', 'S4-ioSc6s(=3-i]oc2lc+H66NFbSFls(-#-P5F', 'cSSBiF6sci6--iiii73c66rcIeH2H-i#+eS6-r6', 'OF4c6SlF6]e67Iiiis[cisl-HbSSi26H6c=r7)', 'icci+([NlISI(3cr[i]7SF]ci(Iici27i6l6', '7HlOSF6osNr]S6p672S[lsHcHiI6H6#6s4l', 'Hiel]F-H6i6In+=i3F--=6-776Fbsic6Fc+HS', 'b]6s2Fl6Ss772e[6I62S4sPci2P-OF-i6', 'c25rNFs66iliObeoSFHiHrSsI6SCsi-(l7F]HF', '6S76FSisslHsiinss--H6F-cis-i]e]SiiSc', 'Ii6sB6lFBb-HN(l=irFli(+6FN6ls17rrFs-F', '6eSN=r6cS67(el6iH16lSFrC6l[77I[#6-pi', 'F-6Hi(cbsHii-SH--bSsS-Hs5FNe5S[iIS(1', 'F6p#7-+r-lSHiiHbSSspH63cs[FlNHiHFI', '-[6ObS666cbF[H6FI[P2sSFB66cHSC-46C-5s', '-Nil6iPisCFrFNH6F-2Pl+BP6-4r6O2sSiscir', '7[#s2##ssFi26#cip-26F66I6FOilcBiNFs', 'rF67ciFNH#pSHFn2r66[64lcc6[56F[O2l6', ']ciiBp1-I[F-i7Fi6F[FNSC+lIcFSe66r]-F77H', 'sFHPOilcH2i2FlBr[)#i7NH-FFccl6i)rH6', 'I#l6P2S7iici-Foi[i6FHs2sseSPI6#l4#i6', 'HF2isiliIH6]CP+i-6]26SHclcril]iFisSip', '-ccsi#cl5B6ci3FiO-FNcPsi72F[OcPiec3s+[', 's-77ccF6Fi6ls27eFbl7F7ii]c661F-266cFO', '=eii(iOSN66liPsFF675]ir-Sn]OoSFHFNiic=[', 'i]iFSi[N7lFeF36c2lSeH[lclP7c667=irNb6[', 'e6bcBcri77#6b6lce+Fl)lss(cc=-F6[F', 'SSr7HFrlN2isSFFNcs7l5ciliiOSli#ii', '2ie]FSe6+HHiIcccb77eFce#lr6S7l6++-[', '2#iicFiBnO6-3ll6cFncH7S[iIoS#-7iiii6', ')cNHcFP=#+HliS-6F[c]Fp6]67sb[2F=iisF7', 'li(c]csirFiHir[-lc+i6cSF]sirCl6lii6[6', 'FB2i=62rO2=ccS6rPocip6sBib666-Hi26c', 'BSF2Hc3-s[e2csN#]SH6[-iO6[SHPPI6]66', 'erH62l(F]cic7-7cc+cc2r7-#SSSFrH#s2S']\n"
     ]
    }
   ],
   "source": [
    "NUM_GENERATE = 1000\n",
    "\n",
    "z = torch.randn(NUM_GENERATE, max_len, 128).to(device) \n",
    "target = torch.zeros(NUM_GENERATE, 1, dtype=torch.long).to(device) \n",
    "\n",
    "for i in range(max_len - 1) :\n",
    "    out = model.inference(z, target) \n",
    "    _, idx = torch.topk(out, 1, dim = -1) \n",
    "    idx = idx[:, -1, :]\n",
    "    target = torch.cat([target, idx], dim = 1)\n",
    "\n",
    "target = target.cpu().tolist()\n",
    "generated_smiles = []\n",
    "\n",
    "for t in target :\n",
    "    smiles = ''.join([inv_dic[i] for i in t])\n",
    "    smiles = smiles.replace(\"<START>\", \"\").replace(\"<PAD>\", \"\").replace(\"<END>\",\"\")\n",
    "\n",
    "    generated_smiles.append(smiles) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_valid(gen_list) : \n",
    "    count = 0\n",
    "    for m in gen_list : \n",
    "        if rdkit.Chem.MolFromSmiles(m) != None : count += 1\n",
    "    return (count / gen_list) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
