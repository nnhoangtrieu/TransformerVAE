{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import rdkit \n",
    "import multiprocessing\n",
    "import copy\n",
    "import math \n",
    "import random\n",
    "import pickle \n",
    "import utils \n",
    "import model \n",
    "from utils import parallel_f, get_mol, replace_atom, tokenize, pad, MyDataset, get_dic\n",
    "from model import TransformerVAE, device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/chembl24_canon_train.pickle', 'rb') as file :\n",
    "    smi_list = pickle.load(file) \n",
    "\n",
    "random.shuffle(smi_list)\n",
    "smi_list = smi_list[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mol_list = parallel_f(get_mol, smi_list)\n",
    "\n",
    "smi_list = parallel_f(replace_atom, smi_list)\n",
    "smi_dic = get_dic(smi_list)\n",
    "inv_dic = {v:k for k, v in smi_dic.items()}\n",
    "token_list = parallel_f(tokenize, smi_list)\n",
    "\n",
    "max_len = len(max(token_list, key=len))\n",
    "token_list = parallel_f(pad, token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "dataset = MyDataset(token_list)\n",
    "\n",
    "train_set, val_set = random_split(dataset, [0.95, 0.05])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerVAE(1024, 128, 8, 0.5, len(smi_dic)).to(device)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.0001) \n",
    "\n",
    "NUM_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train loss : 627881.4107218013 val loss : 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCH + 1) :\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    for input in train_loader :\n",
    "        input = input.to(device)\n",
    "        output = model(input, input[:, :-1])\n",
    "\n",
    "        loss = loss_fn(output.reshape(-1, len(smi_dic)), input[:, 1:].reshape(-1)) + model.first_encoder.kl\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    # model.eval()\n",
    "    # for input in val_loader :\n",
    "    #     input = input.to(device)\n",
    "    #     output = model(input, input[:, :-1])\n",
    "    #     loss = loss_fn(output.reshape(-1, len(smi_dic)), input[:, 1:].reshape(-1)) + model.first_encoder.kl\n",
    "    #     val_loss += loss.item()\n",
    "    print(f'epoch : {epoch}, train loss : {train_loss / len(train_loader)} val loss : {val_loss / len(val_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>CCC(C(=CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1)cccc1)C(=O)NCCC(C(=O)NCCCCC(CCC)C)C)CCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C)cc1)C(=O)NC(CC)C)C)cc1ccc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCC(C(=CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C)cc1)C(=O)NC(CC)C)C)cc1ccc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1)C(=O)CCC(C)C)C)cc1ccc1cccc1)C(=O)NCCCCCC(C(=O)NCCCCCCCC(C(=O)NC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>CCC(=O)cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1)cccc1)C(=O)NCCCC(CCC)C)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCC(F)c1cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "<START>CCC(C(=CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "encoder = model.second_encoder\n",
    "decoder = model.decoder\n",
    "\n",
    "\n",
    "for _ in range(30) :\n",
    "    z = torch.randn(1, max_len, 128).to(device)\n",
    "    target = torch.zeros(1, 1, dtype=torch.long).to(device)\n",
    "\n",
    "    for i in range(max_len - 1) :\n",
    "        memory = encoder(z) \n",
    "        out = decoder(memory, target)\n",
    "        _, idx = torch.topk(out, 1, dim = -1)\n",
    "        idx = idx[:, -1, :]\n",
    "        target = torch.cat([target, idx], dim = 1)\n",
    "\n",
    "    target = target.squeeze(0).tolist()\n",
    "    smiles = ''.join([inv_dic[i] for i in target])\n",
    "    print(smiles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_mol('C(=O)NC(=O)NC(=O)NC(=O)NC(=O)NC(=O)N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
