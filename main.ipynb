{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import rdkit \n",
    "import multiprocessing\n",
    "import copy\n",
    "import math \n",
    "import random\n",
    "import pickle \n",
    "import utils \n",
    "import model \n",
    "from utils import parallel_f, get_mol, replace_atom, tokenize, pad, MyDataset, get_dic\n",
    "from model import TransformerVAE, device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smi_list(path) :\n",
    "    with open(path, 'r') as file :\n",
    "        return [smi[:-1] for smi in file.readlines()]\n",
    "    \n",
    "\n",
    "def replace_atom(smi) :\n",
    "    return smi.replace('Cl', 'L').replace('Br', 'R') \n",
    "\n",
    "def get_mol(smi) :\n",
    "    return rdkit.Chem.MolFromSmiles(smi)\n",
    "\n",
    "def parallel_f(f, input_list) :\n",
    "    pool = multiprocessing.Pool()\n",
    "    return pool.map(f, input_list)\n",
    "\n",
    "def get_dic(smi_list) :\n",
    "    dic = {'<START>': 0, '<END>': 1, '<PAD>': 2}\n",
    "    for smi in smi_list :\n",
    "        for char in smi :\n",
    "            if char not in dic :\n",
    "                dic[char] = len(dic) \n",
    "    return dic \n",
    "\n",
    "def tokenize(smi) :\n",
    "    return [0] + [smi_dic[char] for char in smi] + [1]\n",
    "\n",
    "def pad(smi) :\n",
    "    return smi + [2] * (max_len - len(smi))\n",
    "\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0\n",
    "\n",
    "\n",
    "def get_mask(target) :\n",
    "    mask = (target != smi_dic['<PAD>']).unsqueeze(-2)\n",
    "    return mask & subsequent_mask(target.size(-1)).type_as(mask.data)\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, token_list) :\n",
    "        self.token_list = token_list\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.token_list)\n",
    "\n",
    "    def __getitem__(self, idx) :   \n",
    "        return torch.tensor(self.token_list[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 373814\n"
     ]
    }
   ],
   "source": [
    "# Load ChEMBL dataset\n",
    "\n",
    "with open('data/chembl24_canon_train.pickle', 'rb') as file :\n",
    "    smi_list = pickle.load(file) \n",
    "\n",
    "\n",
    "smi_list = [smi for smi in smi_list if len(smi) < 40] # Choose only smiles with length < 40\n",
    "\n",
    "print(f'Number of data: {len(smi_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# parallel_f is a function for multiprocessing on CPU to speed up the process\n",
    "\n",
    "mol_list = parallel_f(get_mol, smi_list)\n",
    "\n",
    "smi_list = parallel_f(replace_atom, smi_list)\n",
    "\n",
    "smi_dic = get_dic(smi_list)\n",
    "\n",
    "\n",
    "inv_dic = {v:k for k, v in smi_dic.items()}\n",
    "\n",
    "token_list = parallel_f(tokenize, smi_list)\n",
    "max_len = len(max(token_list, key=len))\n",
    "token_list = parallel_f(pad, token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = MyDataset(token_list)\n",
    "train_set, val_set = random_split(dataset, [0.95, 0.05])\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class Attention(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head) :\n",
    "        super(Attention, self).__init__()\n",
    "        assert dim_model % num_head == 0, 'dim_model % num_head != 0'\n",
    "        self.dim_model = dim_model\n",
    "        self.num_head = num_head\n",
    "        self.dim_head = dim_model // num_head\n",
    "\n",
    "        self.Q = nn.Linear(dim_model, dim_model)\n",
    "        self.K = nn.Linear(dim_model, dim_model)\n",
    "        self.V = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "        self.out = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask = None) :\n",
    "        B = Q.size(0) \n",
    "\n",
    "        Q, K, V = self.Q(Q), self.K(K), self.V(V)\n",
    "\n",
    "        len_Q, len_K, len_V = Q.size(1), K.size(1), V.size(1)\n",
    "\n",
    "        Q = Q.reshape(B, self.num_head, len_Q, self.dim_head)\n",
    "        K = K.reshape(B, self.num_head, len_K, self.dim_head)\n",
    "        V = V.reshape(B, self.num_head, len_V, self.dim_head)\n",
    "        \n",
    "        K_T = K.transpose(2,3).contiguous()\n",
    "\n",
    "        attn_score = Q @ K_T\n",
    "\n",
    "        attn_score = attn_score / (self.dim_head ** 1/2)\n",
    "        if mask is not None :\n",
    "            attn_score = attn_score.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn_distribution = torch.softmax(attn_score, dim = -1)\n",
    "\n",
    "        attn = attn_distribution @ V\n",
    "\n",
    "        attn = attn.reshape(B, len_Q, self.num_head * self.dim_head)\n",
    "        \n",
    "        attn = self.out(attn)\n",
    "\n",
    "        return attn, attn_distribution\n",
    "    \n",
    "\n",
    "class FirstEncoder(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_latent, num_head, dropout, vocab_size) :\n",
    "        super(FirstEncoder, self).__init__()\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, dim_model)\n",
    "        self.pos = PositionalEncoding(dim_model, dropout) \n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_model)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.self_attn = Attention(dim_model, num_head) \n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(dim_model, dim_model)\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_model)\n",
    "\n",
    "        self.mu, self.sigma = nn.Linear(dim_model, dim_latent), nn.Linear(dim_model, dim_latent)\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.cuda() \n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.embed(x) * (self.dim_model ** 0.5) \n",
    "        x = self.pos(x)\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        attn, self_attn = self.self_attn(x, x, x)\n",
    "        x = x + self.drop1(attn)\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_foward(x)\n",
    "        x = x + self.drop2(x)   \n",
    "\n",
    "        x = self.norm3(x)\n",
    "\n",
    "        mu, sigma = self.mu(x), torch.exp(self.sigma(x))\n",
    "        z = mu + sigma * self.N.sample(mu.shape)\n",
    "        self.kl = (sigma ** 2 + mu ** 2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "\n",
    "class SecondEncoder(nn.Module) :\n",
    "    def __init__(self, dim_model,  dim_latent, num_head, dropout) :\n",
    "        super(SecondEncoder, self).__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_latent)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.self_attn = Attention(dim_latent, num_head) \n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_latent)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_latent, dim_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(dim_model, dim_model)\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_model)\n",
    "    \n",
    "    def forward(self, z) :\n",
    "        z = self.norm1(z)\n",
    "        attn, self_attn = self.self_attn(z, z, z)\n",
    "        z = z + self.drop1(attn)\n",
    "\n",
    "        z = self.norm2(z)\n",
    "        z = self.feed_foward(z)\n",
    "        z = z + self.drop2(z)   \n",
    "\n",
    "        z = self.norm3(z)\n",
    "\n",
    "        return z\n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head, dropout, vocab_size) :\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.dim_model = dim_model\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, dim_model)\n",
    "        self.pos = PositionalEncoding(dim_model, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_model)   \n",
    "        self.self_attn = Attention(dim_model, num_head)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.cross_attn = Attention(dim_model, num_head)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_model)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(dim_model, dim_model),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.norm4 = nn.LayerNorm(dim_model)\n",
    "\n",
    "        self.proj = nn.Linear(dim_model, vocab_size)\n",
    "\n",
    "    def forward(self, memory, target) :\n",
    "        mask = get_mask(target)\n",
    "        mask = mask.unsqueeze(1).to(device)\n",
    "\n",
    "        target = self.embed(target) * (self.dim_model ** 0.5)\n",
    "        target = self.pos(target)\n",
    "\n",
    "        target = self.norm1(target)\n",
    "        attn, self_attn = self.self_attn(target, target, target, mask)\n",
    "        target = target + self.drop1(attn)\n",
    "\n",
    "        target = self.norm2(target)\n",
    "        attn, cross_attn = self.cross_attn(target, memory, memory)\n",
    "        target = target + self.drop2(attn)\n",
    "\n",
    "        target = self.norm3(target)\n",
    "        target = self.feed_foward(target)\n",
    "        target = target + self.drop3(target)\n",
    "\n",
    "        target = self.norm4(target)\n",
    "\n",
    "        target = self.proj(target)\n",
    "        target = F.log_softmax(target, dim = -1)\n",
    "\n",
    "        return target\n",
    "    \n",
    "\n",
    "class TransformerVAE(nn.Module) :\n",
    "    def __init__(self, dim_model, dim_latent, num_head, dropout, vocab_size) :\n",
    "        super(TransformerVAE, self).__init__()\n",
    "\n",
    "        self.first_encoder = FirstEncoder(dim_model, dim_latent, num_head, dropout, vocab_size)\n",
    "        self.pos = PositionalEncoding(dim_latent, dropout)\n",
    "        self.second_encoder = SecondEncoder(dim_model, dim_latent, num_head, dropout)\n",
    "        self.decoder = Decoder(dim_model, num_head, dropout, vocab_size)\n",
    "\n",
    "    def forward(self, x, target) :\n",
    "        z = self.first_encoder(x) \n",
    "        z = self.pos(z)\n",
    "\n",
    "        memory = self.second_encoder(z)\n",
    "        target = self.decoder(memory, target)\n",
    "\n",
    "        return target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerVAE(256, 64, 8, 0.5, len(smi_dic)).to(device)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.001) \n",
    "\n",
    "NUM_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smi_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m train_loader :\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(smi_dic)), \u001b[38;5;28minput\u001b[39m[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39mfirst_encoder\u001b[38;5;241m.\u001b[39mkl\n\u001b[1;32m     10\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/TransformerVAE/model.py:230\u001b[0m, in \u001b[0;36mTransformerVAE.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m    227\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos(z)\n\u001b[1;32m    229\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecond_encoder(z)\n\u001b[0;32m--> 230\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/TransformerVAE/model.py:190\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, memory, target)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, memory, target) :\n\u001b[0;32m--> 190\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    193\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(target) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_model \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/TransformerVAE/utils.py:48\u001b[0m, in \u001b[0;36mget_mask\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mask\u001b[39m(target) :\n\u001b[0;32m---> 48\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m!=\u001b[39m \u001b[43msmi_dic\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;241m&\u001b[39m subsequent_mask(target\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mtype_as(mask\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smi_dic' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCH + 1) :\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    for input in train_loader :\n",
    "        input = input.to(device)\n",
    "        output = model(input, input[:, :-1])\n",
    "\n",
    "        loss = loss_fn(output.reshape(-1, len(smi_dic)), input[:, 1:].reshape(-1)) + model.first_encoder.kl\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    # model.eval()\n",
    "    # for input in val_loader :\n",
    "    #     input = input.to(device)\n",
    "    #     output = model(input, input[:, :-1])\n",
    "    #     loss = loss_fn(output.reshape(-1, len(smi_dic)), input[:, 1:].reshape(-1)) + model.first_encoder.kl\n",
    "    #     val_loss += loss.item()\n",
    "    print(f'epoch : {epoch}, train loss : {train_loss / len(train_loader)} val loss : {val_loss / len(val_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>CCC(C(=CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1)cccc1)C(=O)NCCC(C(=O)NCCCCC(CCC)C)C)CCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C)cc1)C(=O)NC(CC)C)C)cc1ccc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCC(C(=CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C)cc1)C(=O)NC(CC)C)C)cc1ccc1<END><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1)C(=O)CCC(C)C)C)cc1ccc1cccc1)C(=O)NCCCCCC(C(=O)NCCCCCCCC(C(=O)NC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>CCC(=O)cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCC(=O)NC(=O)NC(=O)NC(C)C(C)C)cc1)cccc1)C(=O)NCCCC(CCC)C)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCC(F)c1cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
      "<START>CCC(C(=CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "<START>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "encoder = model.second_encoder\n",
    "decoder = model.decoder\n",
    "\n",
    "\n",
    "for _ in range(30) :\n",
    "    z = torch.randn(1, max_len, 128).to(device)\n",
    "    target = torch.zeros(1, 1, dtype=torch.long).to(device)\n",
    "\n",
    "    for i in range(max_len - 1) :\n",
    "        memory = encoder(z) \n",
    "        out = decoder(memory, target)\n",
    "        _, idx = torch.topk(out, 1, dim = -1)\n",
    "        idx = idx[:, -1, :]\n",
    "        target = torch.cat([target, idx], dim = 1)\n",
    "\n",
    "    target = target.squeeze(0).tolist()\n",
    "    smiles = ''.join([inv_dic[i] for i in target])\n",
    "    print(smiles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_mol('C(=O)NC(=O)NC(=O)NC(=O)NC(=O)NC(=O)N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
